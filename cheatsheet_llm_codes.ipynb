{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a7f01e",
   "metadata": {},
   "source": [
    "## Loading Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fac10",
   "metadata": {},
   "source": [
    "## LLM APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f92d8",
   "metadata": {},
   "source": [
    "### OpenAI Env, Model, and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "llm.invoke(\"hello how are you my firend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3db15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "len(embeddings.embed_query(\"hello how are you my firend?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353929d",
   "metadata": {},
   "source": [
    "### Groq KEY and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response=llm.invoke(\"what is length of wall of china?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963e118",
   "metadata": {},
   "source": [
    "### Google Gemini Env, Model, and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf211b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0390feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "\n",
    "output = model.invoke(\"hi\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "embeddings.embed_query(\"Hello AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0249749",
   "metadata": {},
   "source": [
    "## Hugging Face Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "len(embeddings.embed_query(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330dd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text=\"this is atest documents\"\n",
    "query_result=embeddings.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f800701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e437169",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffd335",
   "metadata": {},
   "source": [
    "### WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# For 1 URL\n",
    "url = ''\n",
    "web_loader=WebBaseLoader(url)\n",
    "data=web_loader.load()\n",
    "\n",
    "# For Multi URL\n",
    "urls = ['', '']\n",
    "docs=[WebBaseLoader(url).load() for url in urls]\n",
    "docs_list=[item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf62c2",
   "metadata": {},
   "source": [
    "### TextLoader and DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ceef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "loader=DirectoryLoader(\"../data\",glob=\"./*.txt\",loader_cls=TextLoader)\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d817f9",
   "metadata": {},
   "source": [
    "### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader('syllabus.pdf')\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11c68d",
   "metadata": {},
   "source": [
    "### ArXiv Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "docs = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d570177",
   "metadata": {},
   "source": [
    "### Wikipedia Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5868bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"Generative AI\", load_max_docs=4).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39272361",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90c597",
   "metadata": {},
   "source": [
    "### RecursiveCharaterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d012e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Normal Embedding Models\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# OpenAI Embedding Models\n",
    "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder\n",
    "(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=25\n",
    ")\n",
    "\n",
    "# Common Code\n",
    "doc_splits=text_splitter.split_documents(docs_list)\n",
    "\n",
    "\n",
    "# If only page content needed\n",
    "doc_string=[doc.page_content for doc in doc_splits]\n",
    "\n",
    "# If need to preserve metadata\n",
    "texts = [doc.page_content for doc in doc_splits]\n",
    "metadatas = [doc.metadata for doc in doc_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e4bb7",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=100,chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0173008",
   "metadata": {},
   "source": [
    "### HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e02bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Foo</h1>\n",
    "        <p>Some intro text about Foo.</p>\n",
    "        <div>\n",
    "            <h2>Bar main section</h2>\n",
    "            <p>Some intro text about Bar.</p>\n",
    "            <h3>Bar subsection 1</h3>\n",
    "            <p>Some text about the first subtopic of Bar.</p>\n",
    "            <h3>Bar subsection 2</h3>\n",
    "            <p>Some text about the second subtopic of Bar.</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Baz</h2>\n",
    "            <p>Some text about Baz</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Some concluding text about Foo</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b96f4",
   "metadata": {},
   "source": [
    "### RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "json_splitter=RecursiveJsonSplitter(max_chunk_size=300)\n",
    "json_chunks=json_splitter.split_json(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e7565",
   "metadata": {},
   "source": [
    "## Vector Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c01489",
   "metadata": {},
   "source": [
    "### FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# Using Inner Product in FAISS Index\n",
    "\n",
    "index=faiss.IndexFlatIP(3072) # Number of dimensions in the embedding model\n",
    "\n",
    "db = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# Using Euclidiean Distance in FAISS Index\n",
    "\n",
    "index=faiss.IndexFlatL2(384) # Number of dimensions in the embedding model\n",
    "\n",
    "db = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# If we just need the docstrings\n",
    "db.add_texts(doc_string)\n",
    "\n",
    "# If we need to add metadata info as well\n",
    "db.add_texts(texts, metadatas=metadatas)\n",
    "\n",
    "# Note: Add texts only works with array of docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1318c",
   "metadata": {},
   "source": [
    "### Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore=Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chrome\", # Any Name\n",
    "    embedding=embeddings\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593aefa5",
   "metadata": {},
   "source": [
    "### Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec  #Serverless: Server will be Managed by the cloud provider\n",
    "\n",
    "pc=Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Index Creation and Loading\n",
    "\n",
    "index_name=\"agentic-ai\"\n",
    "\n",
    "#creating a index\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")    \n",
    ")\n",
    "\n",
    "#loading the index\n",
    "index=pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13002883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Vector Store and Similarity Search\n",
    "vector_store=PineconeVectorStore(index=index,embedding=embeddings)\n",
    "\n",
    "results = vector_store.similarity_search(\"what is a langchain?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e99f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store Retriever\n",
    "\n",
    "retriever=vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.7} #hyperparameter\n",
    ")\n",
    "retriever.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc8423",
   "metadata": {},
   "source": [
    "## Langchain Inbuilt Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb92c74",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b23eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max= 500)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper= api_wrapper)\n",
    "\n",
    "# To get tool name\n",
    "wiki_tool.name\n",
    "# To get tool description\n",
    "wiki_tool.description\n",
    "# To get tool args\n",
    "wiki_tool.args\n",
    "\n",
    "# Running\n",
    "wiki_tool.run({\"query\": \"elon musk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46432b85",
   "metadata": {},
   "source": [
    "### Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "tool = YouTubeSearchTool()\n",
    "\n",
    "# To get tool name\n",
    "tool.name\n",
    "# To get tool description\n",
    "tool.description\n",
    "# To get tool args\n",
    "tool.args\n",
    "\n",
    "# Running\n",
    "tool.run(\"Emergency Awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59299f25",
   "metadata": {},
   "source": [
    "### Tavily (Search Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591921c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "# Running - 1\n",
    "tool.invoke({\"query\":\"what happend between Trump and Musk today?\"})\n",
    "\n",
    "# Running - 2\n",
    "question = \"what happend between Trump and Musk today?\"\n",
    "complete_query = \"Anwer the follow question by searching the internet and getting best response. Following is the user question: \" + question\n",
    "\n",
    "tool.invoke(complete_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d10122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_tool=TavilySearch(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "question = \"what happend between Trump and Musk today?\"\n",
    "complete_query = \"Anwer the follow question by searching the internet and getting best response. Following is the user question: \" + question\n",
    "\n",
    "tavily_tool.invoke(complete_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a88ffe0",
   "metadata": {},
   "source": [
    "### DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.invoke(\"what is the latest update on iphone17 release?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be3b43",
   "metadata": {},
   "source": [
    "## Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59822c6",
   "metadata": {},
   "source": [
    "### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The Sum of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38b8fa",
   "metadata": {},
   "source": [
    "### Subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Subtract two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The difference of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1bbda",
   "metadata": {},
   "source": [
    "### Absolute Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f35cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def abs_diff(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Subtract two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The absolute difference of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return abs(a - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b2318",
   "metadata": {},
   "source": [
    "### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65aa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiple(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiple two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The product of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a6e9b",
   "metadata": {},
   "source": [
    "### Divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Divide two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The result of division\n",
    "    \"\"\"\n",
    "\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Denominator cannot be zero.\")\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f9fa7",
   "metadata": {},
   "source": [
    "### Length of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length(word:str)->int:\n",
    "    \"\"\"\n",
    "    Calculate the length of the word.\n",
    "\n",
    "    Args:\n",
    "    word(str): The word in string\n",
    "\n",
    "    Returns:\n",
    "        int: The length of the word\n",
    "    \"\"\"\n",
    "    return len(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
