{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e8e69b",
   "metadata": {},
   "source": [
    "# Complete LLM Cheatsheet with RAG and Agents (using Langgraph)\n",
    "\n",
    "- LLM APIs\n",
    "- Huggingface Embedding Models\n",
    "- Data Loaders\n",
    "- Chunking\n",
    "- Vector Embedding using FAISS, Chroma, and Pinecone\n",
    "- Langchain Inbuilt Tools\n",
    "- Creating custom tools\n",
    "- Agentic Orchestration\n",
    "- ReAct Agents\n",
    "- Agentic RAG\n",
    "- MultiAgents (Network and Supervisor)\n",
    "- Human in Loop and Misc. Manipulations with Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7f01e",
   "metadata": {},
   "source": [
    "## Loading Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6bfb7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fac10",
   "metadata": {},
   "source": [
    "## LLM APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f92d8",
   "metadata": {},
   "source": [
    "### OpenAI Env, Model, and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "llm.invoke(\"hello how are you my firend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3db15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "len(embeddings.embed_query(\"hello how are you my firend?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353929d",
   "metadata": {},
   "source": [
    "### Groq KEY and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0d73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8630a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response=llm.invoke(\"what is length of wall of china?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963e118",
   "metadata": {},
   "source": [
    "### Google Gemini Env, Model, and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf211b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0390feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "\n",
    "output = model.invoke(\"hi\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "embeddings.embed_query(\"Hello AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0249749",
   "metadata": {},
   "source": [
    "## Hugging Face Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "len(embeddings.embed_query(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330dd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text=\"this is atest documents\"\n",
    "query_result=embeddings.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f800701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e437169",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffd335",
   "metadata": {},
   "source": [
    "### WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# For 1 URL\n",
    "url = ''\n",
    "web_loader=WebBaseLoader(url)\n",
    "data=web_loader.load()\n",
    "\n",
    "# For Multi URL\n",
    "urls = ['', '']\n",
    "docs=[WebBaseLoader(url).load() for url in urls]\n",
    "docs_list=[item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf62c2",
   "metadata": {},
   "source": [
    "### TextLoader and DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ceef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "loader=DirectoryLoader(\"../data\",glob=\"./*.txt\",loader_cls=TextLoader)\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d817f9",
   "metadata": {},
   "source": [
    "### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader('syllabus.pdf')\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df11c68d",
   "metadata": {},
   "source": [
    "### ArXiv Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "docs = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d570177",
   "metadata": {},
   "source": [
    "### Wikipedia Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5868bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"Generative AI\", load_max_docs=4).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39272361",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90c597",
   "metadata": {},
   "source": [
    "### RecursiveCharaterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d012e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Normal Embedding Models\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# OpenAI Embedding Models\n",
    "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder\n",
    "(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=25\n",
    ")\n",
    "\n",
    "# Common Code\n",
    "doc_splits=text_splitter.split_documents(docs_list)\n",
    "\n",
    "\n",
    "# If only page content needed\n",
    "doc_string=[doc.page_content for doc in doc_splits]\n",
    "\n",
    "# If need to preserve metadata\n",
    "texts = [doc.page_content for doc in doc_splits]\n",
    "metadatas = [doc.metadata for doc in doc_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e4bb7",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=100,chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0173008",
   "metadata": {},
   "source": [
    "### HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e02bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Foo</h1>\n",
    "        <p>Some intro text about Foo.</p>\n",
    "        <div>\n",
    "            <h2>Bar main section</h2>\n",
    "            <p>Some intro text about Bar.</p>\n",
    "            <h3>Bar subsection 1</h3>\n",
    "            <p>Some text about the first subtopic of Bar.</p>\n",
    "            <h3>Bar subsection 2</h3>\n",
    "            <p>Some text about the second subtopic of Bar.</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Baz</h2>\n",
    "            <p>Some text about Baz</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Some concluding text about Foo</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b96f4",
   "metadata": {},
   "source": [
    "### RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "json_splitter=RecursiveJsonSplitter(max_chunk_size=300)\n",
    "json_chunks=json_splitter.split_json(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e7565",
   "metadata": {},
   "source": [
    "## Vector Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c01489",
   "metadata": {},
   "source": [
    "### FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# Using Inner Product in FAISS Index\n",
    "\n",
    "index=faiss.IndexFlatIP(3072) # Number of dimensions in the embedding model\n",
    "\n",
    "db = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# Using Euclidiean Distance in FAISS Index\n",
    "\n",
    "index=faiss.IndexFlatL2(384) # Number of dimensions in the embedding model\n",
    "\n",
    "db = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "# If we just need the docstrings\n",
    "db.add_texts(doc_string)\n",
    "\n",
    "# If we need to add metadata info as well\n",
    "db.add_texts(texts, metadatas=metadatas)\n",
    "\n",
    "# Note: Add texts only works with array of docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a30fa4",
   "metadata": {},
   "source": [
    "### Saving and Loading Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79467d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Index\n",
    "\n",
    "db.save_local(\"saved_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a090255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Index\n",
    "\n",
    "new_vector_store=FAISS.load_local(\n",
    "  \"saved_index\",\n",
    "  embeddings,\n",
    "  allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1318c",
   "metadata": {},
   "source": [
    "### Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore=Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chrome\", # Any Name\n",
    "    embedding=embeddings\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593aefa5",
   "metadata": {},
   "source": [
    "### Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a8f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec  #Serverless: Server will be Managed by the cloud provider\n",
    "\n",
    "pc=Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Index Creation and Loading\n",
    "\n",
    "index_name=\"agentic-ai\"\n",
    "\n",
    "#creating a index\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")    \n",
    ")\n",
    "\n",
    "#loading the index\n",
    "index=pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13002883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Vector Store and Similarity Search\n",
    "vector_store=PineconeVectorStore(index=index,embedding=embeddings)\n",
    "\n",
    "results = vector_store.similarity_search(\"what is a langchain?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e99f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store Retriever\n",
    "\n",
    "retriever=vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.7} #hyperparameter\n",
    ")\n",
    "retriever.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc8423",
   "metadata": {},
   "source": [
    "## Langchain Inbuilt Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb92c74",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b23eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max= 500)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper= api_wrapper)\n",
    "\n",
    "# To get tool name\n",
    "wiki_tool.name\n",
    "# To get tool description\n",
    "wiki_tool.description\n",
    "# To get tool args\n",
    "wiki_tool.args\n",
    "\n",
    "# Running\n",
    "wiki_tool.run({\"query\": \"elon musk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46432b85",
   "metadata": {},
   "source": [
    "### Youtube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "tool = YouTubeSearchTool()\n",
    "\n",
    "# To get tool name\n",
    "tool.name\n",
    "# To get tool description\n",
    "tool.description\n",
    "# To get tool args\n",
    "tool.args\n",
    "\n",
    "# Running\n",
    "tool.run(\"Emergency Awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59299f25",
   "metadata": {},
   "source": [
    "### Tavily (Search Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591921c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "# Running - 1\n",
    "tool.invoke({\"query\":\"what happend between Trump and Musk today?\"})\n",
    "\n",
    "# Running - 2\n",
    "question = \"what happend between Trump and Musk today?\"\n",
    "complete_query = \"Anwer the follow question by searching the internet and getting best response. Following is the user question: \" + question\n",
    "\n",
    "tool.invoke(complete_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d10122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_tool=TavilySearch(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "question = \"what happend between Trump and Musk today?\"\n",
    "complete_query = \"Anwer the follow question by searching the internet and getting best response. Following is the user question: \" + question\n",
    "\n",
    "tavily_tool.invoke(complete_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a88ffe0",
   "metadata": {},
   "source": [
    "### DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.invoke(\"what is the latest update on iphone17 release?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e29e3e",
   "metadata": {},
   "source": [
    "### Python REPL Utililty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b180b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run any given python code\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "code = \"\"\"\n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\"\n",
    "\n",
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be3b43",
   "metadata": {},
   "source": [
    "## Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59822c6",
   "metadata": {},
   "source": [
    "### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The Sum of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38b8fa",
   "metadata": {},
   "source": [
    "### Subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Subtract two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The difference of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1bbda",
   "metadata": {},
   "source": [
    "### Absolute Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f35cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def abs_diff(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Subtract two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The absolute difference of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return abs(a - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b2318",
   "metadata": {},
   "source": [
    "### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65aa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiple(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiple two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The product of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a6e9b",
   "metadata": {},
   "source": [
    "### Divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Divide two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The result of division\n",
    "    \"\"\"\n",
    "\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Denominator cannot be zero.\")\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f9fa7",
   "metadata": {},
   "source": [
    "### Length of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_word_length(word:str)->int:\n",
    "    \"\"\"\n",
    "    Calculate the length of the word.\n",
    "\n",
    "    Args:\n",
    "    word(str): The word in string\n",
    "\n",
    "    Returns:\n",
    "        int: The length of the word\n",
    "    \"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c04654",
   "metadata": {},
   "source": [
    "## Agentic Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816fa5f",
   "metadata": {},
   "source": [
    "### Pydantic Class for some kind of validation -> used as an Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel , Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic:str=Field(description=\"selected topic\")\n",
    "    Reasoning:str=Field(description='Reasoning behind topic selection')\n",
    "\n",
    "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31f5a6",
   "metadata": {},
   "source": [
    "### Custom Agent State Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f824a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aed967f",
   "metadata": {},
   "source": [
    "### Prebuilt Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16220d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "\n",
    "workflow = StateGraph(MessagesState) \n",
    "# This is the same as our custom defined Agent State Function (right now), if we need something custom, we can use our methods, else MessageState is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6aafff",
   "metadata": {},
   "source": [
    "### Workflow 1: Agentic Orchestration using parser(pydantic class), custom AgentState, and Custom Router Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef0e6d",
   "metadata": {},
   "source": [
    "![alt text](01a93893-3dce-4f90-80d0-b335c9bd36a2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# LLM Supervisor Function using Pydantic Parser, Custom Agent State, Chaining\n",
    "def llm_supervisor_function(state: AgentState):\n",
    "    question = state[\"messages\"][-1]\n",
    "\n",
    "    print(\"Question\", question)\n",
    "\n",
    "    template=\"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [USA, Not Related]. \n",
    "    Only respond with the category name and nothing else.\n",
    "\n",
    "    User query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"question\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions}\n",
    "    )\n",
    "\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    response = chain.invoke({\"question\": question})\n",
    "\n",
    "    print(\"Parsed response\", response)\n",
    "\n",
    "    return {\"messages\": [response.Topic]}\n",
    "\n",
    "# Custom Router Function\n",
    "def router_function(state: AgentState):\n",
    "    print(\"-> Router ->\")\n",
    "\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    print(\"last_message: \", last_message)\n",
    "\n",
    "    if \"usa\" in last_message.lower():\n",
    "        return \"RAG Call\"\n",
    "    else:\n",
    "        return \"LLM Call\"\n",
    "    \n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG Function\n",
    "def function2(state: AgentState):\n",
    "    print(\"-> RAG Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    prompt=PromptTemplate(\n",
    "        template = \"\"\"\n",
    "        You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "        If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\n\n",
    "        Question: {question} \\n\n",
    "        Context: {context} \\n\n",
    "        Answer:\n",
    "        \"\"\",\n",
    "        \n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = rag_chain.invoke(question)\n",
    "    return  {\"messages\": [result]}\n",
    "\n",
    "# LLM Function\n",
    "def function3(state: AgentState):\n",
    "    print(\"-> LLM Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    # Normal LLM call\n",
    "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
    "    response = model.invoke(complete_query)\n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"Supervisor\", llm_supervisor_function)\n",
    "workflow.add_node(\"RAG\", function2)\n",
    "workflow.add_node(\"LLM\", function3)\n",
    "\n",
    "# One Way\n",
    "workflow.set_entry_point(\"Supervisor\")\n",
    "\n",
    "# Other Way\n",
    "workflow.add_edge(START, \"Supervisor\")\n",
    "\n",
    "# When Conditional Edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"Supervisor\",\n",
    "    router_function,\n",
    "    {\n",
    "        \"RAG Call\" : \"RAG\",\n",
    "        \"LLM Call\" : \"LLM\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"RAG\", END)\n",
    "workflow.add_edge(\"LLM\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861717c9",
   "metadata": {},
   "source": [
    "### Workflow 2: Agentic Orchestration Using Message State, Tool Node, Custom Tools, Multi Tool Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b70d9",
   "metadata": {},
   "source": [
    "![alt text](95f33936-ba48-4300-9742-488a7f1cd6f3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,MessagesState,START,END\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cabf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tool\n",
    "\n",
    "@tool\n",
    "def search(query:str):\n",
    "    \"\"\"this is my custom tool for searching a weather\"\"\"\n",
    "    if \"delhi\" in query.lower():\n",
    "        return \"the temp is 45 degree celsius\"\n",
    "    return \"the temp is 25 degree celsius\"\n",
    "\n",
    "# Binding Tool\n",
    "tools = [search]\n",
    "llm_with_tool = llm.bind_tools(tools)\n",
    "\n",
    "response = llm_with_tool.invoke(\"what is weather in delhi?\")\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a94c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Message State\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    question = state['messages']\n",
    "    response = llm_with_tool.invoke(question)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Custom Router Function, which will be replaced by langgraph.prebuilt tools_condition \n",
    "def router_function(state: MessagesState):\n",
    "    message = state[\"messages\"]\n",
    "    last_message = message[-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tool Node from Tool Node class\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0958a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow2 = StateGraph(MessagesState)\n",
    "workflow2.add_node(\"llmwithtool\",call_model)\n",
    "workflow2.add_node(\"mytools\", tool_node) # The tool Node is used here\n",
    "workflow2.add_edge(START, \"llmwithtool\")\n",
    "workflow2.add_conditional_edges(\"llmwithtool\",\n",
    "                                router_function,\n",
    "                                {\"tools\": \"mytools\",\n",
    "                                END: END})\n",
    "workflow2.add_edge(\"mytools\", \"llmwithtool\") # This edge makes multi tool call\n",
    "app2 = workflow2.compile()\n",
    "app2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e3fde4",
   "metadata": {},
   "source": [
    "### Using tools_condition instead of our custom Router function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using router_function in the add_condition_edges method, use tools_condition. This is a inbuilt function in langgraph which returns \"tools\" (same as in our router function)\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "workflow.add_conditional_edges(\"llmwithtool\",\n",
    "                            tools_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d53158",
   "metadata": {},
   "source": [
    "### Use of Memory Saver, Stream Messages, and Pretty Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44220118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Only need to add checkpointer to this memory \n",
    "app2 = workflow2.compile(checkpointer=memory)\n",
    "app2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656366a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Creating this events \n",
    "events = app2.stream(\n",
    "    {\"messages\":[\"what is a weather in delhi can you tell me some good hotel for staying in north delhi\"]}, \n",
    "    config=config, \n",
    "    stream_mode=\"values\"\n",
    "    )\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc0a1b",
   "metadata": {},
   "source": [
    "### Viewing Compiled Workflow stored in app variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef35649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320b661",
   "metadata": {},
   "source": [
    "### Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ff158",
   "metadata": {},
   "source": [
    "![alt text](004a619e-f184-41ff-b629-ecdad04b9eb0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Retrieval Step until Vector Embedding creation and adding the doc list to it\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0873d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Adding retriever as a tool\n",
    "retriever_tool=create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_blog_post\", # Any Name\n",
    "    \"vector database data description, comprehensive for the model to make sense of\", # Description for vector db data\n",
    "    )\n",
    "\n",
    "# Adding to tools and Tool Node Creation\n",
    "tools=[retriever_tool]\n",
    "llm_with_tool=llm.bind_tools(tools)\n",
    "\n",
    "retriever_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94695de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "# Pydantic Class \n",
    "class grade(BaseModel):\n",
    "    binary_score:str=Field(description=\"Relvance score 'yes' or 'no'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "from langchain import hub\n",
    "from typing import Literal\n",
    "#we use it for type of hinting\n",
    "\n",
    "def LLM_Decision_Maker(state:AgentState):\n",
    "    print(\"----CALL LLM_DECISION_MAKE----\")\n",
    "    message=state[\"messages\"]\n",
    "    last_message=message[-1]\n",
    "    question=last_message.content\n",
    "    response=llm_with_tool.invoke(question)\n",
    "    return {\"messages\":[response]}\n",
    "\n",
    "\n",
    "def grade_documents(state:AgentState)->Literal[\"Output Generator\", \"Query Rewriter\"]:\n",
    "    print(\"----CALLING GRADE FOR CHECKING RELEVANCY----\")\n",
    "    llm_with_structure_op=llm.with_structured_output(grade) # To provide response in a certain assigned schema (grade here)\n",
    "    \n",
    "    prompt=PromptTemplate(\n",
    "        template=\"\"\"You are a grader deciding if a document is relevant to a user’s question.\n",
    "                    Here is the document: {context}\n",
    "                    Here is the user’s question: {question}\n",
    "                    If the document talks about or contains information related to the user’s question, mark it as relevant. \n",
    "                    Give a 'yes' or 'no' answer to show if the document is relevant to the question.\"\"\",\n",
    "                    input_variables=[\"context\", \"question\"]\n",
    "                    )\n",
    "     \n",
    "    chain=prompt|llm_with_structure_op\n",
    "     \n",
    "     \n",
    "    message=state['messages']\n",
    "    \n",
    "    last_message = message[-1]\n",
    "    \n",
    "    question = message[0].content\n",
    "    \n",
    "    docs = last_message.content\n",
    "    \n",
    "    scored_result=chain.invoke({\"question\": question, \"context\": docs})\n",
    "    \n",
    "    score=scored_result.binary_score\n",
    "     \n",
    "    if score==\"yes\":\n",
    "        print(\"----DECISION: DOCS ARE RELEVANT----\")\n",
    "        return \"generator\"\n",
    "    else:\n",
    "        print(\"----DECISION: DOCS ARE NOT RELEVANT----\")\n",
    "        return \"rewriter\"\n",
    "    \n",
    "\n",
    "def generate(state:AgentState):\n",
    "    print(\"----RAG OUTPUT GENERATE----\")\n",
    "    \n",
    "    message=state[\"messages\"]\n",
    "    question=message[0].content\n",
    "    \n",
    "    last_message = message[-1]\n",
    "    docs = last_message.content\n",
    "\n",
    "    # To assign a said prompt for the RAG part of code using the preexisting library\n",
    "    prompt=hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    rag_chain=prompt | llm\n",
    "    \n",
    "    response=rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    \n",
    "    print(f\"this is my response:{response}\")\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def rewrite(state:AgentState):\n",
    "    print(\"----TRANSFORM QUERY----\")\n",
    "    message=state[\"messages\"]\n",
    "    \n",
    "    question=message[0].content\n",
    "    \n",
    "    input= [HumanMessage(content=f\"\"\"Look at the input and try to reason about the underlying semantic intent or meaning. \n",
    "                    Here is the initial question: {question} \n",
    "                    Formulate an improved question: \"\"\")\n",
    "       ]\n",
    "\n",
    "    response=llm.invoke(input)\n",
    "    \n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdaa757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic Orchestration\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "workflow=StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"LLM Decision Maker\",LLM_Decision_Maker)\n",
    "workflow.add_node(\"Vector Retriever\",retriever_node)\n",
    "workflow.add_node(\"Output Generator\",generate)\n",
    "workflow.add_node(\"Query Rewriter\",rewrite)\n",
    "\n",
    "workflow.add_edge(START,\"LLM Decision Maker\")\n",
    "workflow.add_conditional_edges(\"LLM Decision Maker\",\n",
    "                               tools_condition,\n",
    "                               {\"tools\":\"Vector Retriever\",\n",
    "                                END:END\n",
    "                                })\n",
    "workflow.add_conditional_edges(\"Vector Retriever\",\n",
    "                               grade_documents,\n",
    "                               {\"generator\":\"Output Generator\",\n",
    "                                \"rewriter\":\"Query Rewriter\"\n",
    "                                })\n",
    "workflow.add_edge(\"Output Generator\",END)\n",
    "workflow.add_edge(\"Query Rewriter\",\"LLM Decision Maker\")\n",
    "\n",
    "app=workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2b2c6",
   "metadata": {},
   "source": [
    "### Invoking created Agentic Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b70263",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"messages\":[\"what is LLM Powered Autonomous Agents explain the planning and reflection and prompt engineering explain me in terms of agents and langchain?\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc603c2",
   "metadata": {},
   "source": [
    "## MultiAgents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f1afb",
   "metadata": {},
   "source": [
    "#### Concept of Command in MultiAgents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7c9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition is 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 30}, goto='multiply')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "def add_number(state):\n",
    "    result = state[\"num1\"] + state[\"num2\"]\n",
    "    print(f\"Addition is {result}\")\n",
    "\n",
    "    return Command(goto=\"multiply\", update = {\"sum\": result}) # Updates the current state, and tells which Agent to go to Next\n",
    "\n",
    "state = {\"num1\": 10, \"num2\": 20}\n",
    "\n",
    "add_number(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c8a88",
   "metadata": {},
   "source": [
    "#### Concept of create_react_agent to use inbuilt library to create an agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dae8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Creates an Agent, with defined LLM, tools, and the PROMPT we provide\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools = [tools_arr],\n",
    "        prompt = \"PROMPT FOR THE AGENT\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3561c9d",
   "metadata": {},
   "source": [
    "### Network/Collaboration MultiAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111cdfc",
   "metadata": {},
   "source": [
    "![alt text](b9c5dea6-b44a-4c74-a92f-9d2642bbd17b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from typing import Annotated\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState,StateGraph, START,END\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ea2e3",
   "metadata": {},
   "source": [
    "#### Tools and Function Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da31808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python REPL Tool Creation to run the code it recieves\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "    ):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "        \n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# A system prompt to tell LLM, adding agent vise context\n",
    "def make_system_prompt(instruction:str)->str:\n",
    "    return  (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{instruction}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Directing the LLM, what to do based on the last_message\n",
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message:\n",
    "        return END\n",
    "    \n",
    "    return goto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1 -> Researcher Node\n",
    "\n",
    "def research_node(state: MessagesState)-> Command[Literal[\"chart_generator\", END]]:\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools = [search_tool],\n",
    "        prompt = make_system_prompt(\n",
    "            \"You can only do research. You are working with a chart generator colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    last_message = result[\"messages\"][-1]\n",
    "\n",
    "    goto=get_next_node(last_message,\"chart_generator\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "\n",
    "    return Command(update= {\"messages\": result[\"messages\"]}, goto = goto)\n",
    "\n",
    "\n",
    "# Agent 2 -> Chart Creation Node\n",
    "\n",
    "def chart_node(state: MessagesState)-> Command[Literal[\"researcher\", END]]:\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools = [python_repl_tool],\n",
    "        prompt = make_system_prompt(\n",
    "            \"You can only generate charts. You are working with a researcher colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = chart_agent.invoke(state)\n",
    "\n",
    "    last_message = result[\"messages\"][-1]\n",
    "\n",
    "    goto=get_next_node(last_message,\"researcher\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"chart_generator\")\n",
    "\n",
    "    return Command(update= {\"messages\": result[\"messages\"]}, goto= goto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6418b",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ed8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "app = workflow.compile()\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af30fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"messages\": [(\"user\",\"get the UK's GDP over the past 3 years, then make a line chart of it.Once you make the chart, finish.\")],})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77e476",
   "metadata": {},
   "source": [
    "### Supervisor MultiAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27988e9",
   "metadata": {},
   "source": [
    "![alt text](a3a4db77-825b-49e9-abdc-ff0bb7255e37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e52e78",
   "metadata": {},
   "source": [
    "#### Tools and Function Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a81a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3045ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1 - Researcher\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "search_tool=TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n",
    "\n",
    "\n",
    "# Tool 2 - Coder\n",
    "repl=PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(code: Annotated[str, \"The python code to execute to generate your chart.\"]):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c34550",
   "metadata": {},
   "outputs": [],
   "source": [
    "members=[\"researcher\",\"coder\"]\n",
    "\n",
    "options = members+[\"FINISH\"]\n",
    "\n",
    "class Router(TypedDict):\n",
    "    next: Literal['researcher', 'coder', 'FINISH']\n",
    "\n",
    "#### IMPORTANT\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "# State will look like this\n",
    "# state={\"messages\": [\"hi\"], \"next\": \"research_agent\"}\n",
    "\n",
    "system_prompt = f\"\"\"\"\n",
    "You are a supervisor, tasked with managing a conversation between the following workers: {members}. \n",
    "Given the following user request, respond with the worker to act next. \n",
    "Each worker will perform a task and respond with their results and status. \n",
    "When finished, respond with FINISH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 1 [SUPERVISOR]\n",
    "\n",
    "def supervisor_agent(state: State)->Command[Literal['researcher', 'coder', '__end__']]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, ] + state[\"messages\"]\n",
    "\n",
    "    llm_with_structured_output = llm.with_structured_output(Router)\n",
    "\n",
    "    response = llm_with_structured_output.invoke(messages)\n",
    "\n",
    "    # this is my next worker agent\n",
    "    goto = response[\"next\"]\n",
    "\n",
    "    print(\"***************BELOW IS MY GOTO****************\")\n",
    "\n",
    "    print(goto)\n",
    "\n",
    "    if goto == \"FINISH\":\n",
    "        return '__end__'\n",
    "    \n",
    "    return Command(goto= goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 2 [RESEARCHER]\n",
    "\n",
    "def researcher_agent(state: State)->Command[Literal['supervisor']]:\n",
    "    research_agent = create_react_agent(llm, tools=[search_tool], prompt=\"You are a researcher. DO NOT do any math.\")\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content = result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT 3 [CODER]\n",
    "\n",
    "def coder_agent(state: State)->Command[Literal['supervisor']]:\n",
    "    code_agent = create_react_agent(llm, tools=[python_repl_tool], prompt=\"You are a coder. DO NOT do any research.\")\n",
    "\n",
    "    result = code_agent.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                HumanMessage(content = result[\"messages\"][-1].content, name = \"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0504c771",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed37d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_agent)\n",
    "graph.add_node(\"researcher\", researcher_agent)\n",
    "graph.add_node(\"coder\", coder_agent)\n",
    "\n",
    "graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb453d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in app.stream({\"messages\": [(\"user\", \"What's the square root of 49?\")]}, subgraphs=True):\n",
    "    print(s)\n",
    "    print(\"**********BELOW IS MY STATE***************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785b367",
   "metadata": {},
   "source": [
    "## Human In Loop and Misc. Agent Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865ce77",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9dc4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb780a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(x: int, y: int) -> int:\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"search the web for a query and return the results\"\"\"\n",
    "    tavily=TavilySearchResults()\n",
    "    result=tavily.invoke(query)\n",
    "    return f\"Result for {query} is: \\n{result}\"\n",
    "\n",
    "\n",
    "tools = [multiply, search]\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafea75",
   "metadata": {},
   "source": [
    "#### New Concept: Handling Tools and Understanding Tool Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e5c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm_with_tools.invoke(\"what is current gdp of india?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b2b5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'args': {'query': 'current GDP of India'},\n",
       "  'id': 'p5t52ta10',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a6f8b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls[0][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5300a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'current GDP of India'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18393b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiply': StructuredTool(name='multiply', description='Multiplies two numbers.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x0000029F52F24540>),\n",
       " 'search': StructuredTool(name='search', description='search the web for a query and return the results', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x0000029F52F242C0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool Mapping\n",
    "\n",
    "tool_mapping={tool.name:tool for tool in tools}\n",
    "tool_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df4045e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='search the web for a query and return the results', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x0000029F52F242C0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_mapping[\"search\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3756f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshit\\AppData\\Local\\Temp\\ipykernel_18004\\1333534694.py:9: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily=TavilySearchResults()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Result for What is the capital of india? is: \\n[{\\'title\\': \\'What is the capital of India? States and union territories explained.\\', \\'url\\': \\'https://www.usatoday.com/story/news/world/2023/05/24/what-is-the-capital-of-india/70195720007/\\', \\'content\\': \\'Want to learn more about the soon-to-be most populous country? Here’s some interesting information about how India is organized.\\\\n\\\\n## What is the capital of India?\\\\n\\\\nThe capital of India is New Delhi, located in the north-central part of the country to the west of the Yamuna River.\\\\n\\\\nCalcutta (now Kolkata, the capital of West Bengal) was the country’s capital until 1911 when King George V declared Delhi the new capital and construction of New Delhi began. [...] When the national government achieved independence in 1947, New Delhi became the capital.\\\\n\\\\nMumbai, the state capital of Maharashtra, is often considered the financial capital of India because of its role in the national and international economy.\\\\n\\\\n## How many states are in India?\\\\n\\\\nIndia is home to 28 states, each with its own capital and run by a Governor who represents the President:\\\\n\\\\nIndia also has eight union territories, governed by an Administrator appointed by the President:\\', \\'score\\': 0.93265617}, {\\'title\\': \\'Which City became the capital of India for a day, Check here\\', \\'url\\': \\'https://www.jagranjosh.com/general-knowledge/which-city-became-the-capital-of-india-for-a-day-1731421925-1\\', \\'content\\': \\'If someone asks you what is the capital of India, you will answer that it is New Delhi, which the British established. In Indian history, the capital of the country changed many times and different cities got the honour of becoming the capital of the country. [...] ## If you are asked what the capital of India is, your answer will be New Delhi, which was settled by the British. Do you know that once in Indian history, a district was made the capital of the country? However, this incident lasted only for a day, after which it was recorded in the pages of history forever. This article will introduce you to one such district in India.\\\\n\\\\nByKishan Kumar\\\\n\\\\nNov 12, 2024, 20:03 IST\\\\n\\\\none day capital of India [...] After making Kolkata its capital, on 12 December 1912, New Delhi was declared as the capital of the country in the presence of George V. Since then, the name of New Delhi has been associated with the capital of the country.\\\\n\\\\nKishan Kumar\\\\n\\\\nSenior content writer\\', \\'score\\': 0.91901255}, {\\'title\\': \\'New Delhi - Wikipedia\\', \\'url\\': \\'https://en.wikipedia.org/wiki/New_Delhi\\', \\'content\\': \\'Appearance\\\\n\\\\nmove to sidebar hide\\\\n\\\\nCoordinates: 28°36′50″N 77°12′32″E / 28.61389°N 77.20889°E / 28.61389; 77.20889\\\\n\\\\nImage 4: Page semi-protected\\\\n\\\\nFrom Wikipedia, the free encyclopedia\\\\n\\\\nCapital city of India\\\\n\\\\nThis article is about the capital of India, within the union territory of Delhi. For other uses, see New Delhi (disambiguation) \"New Delhi (disambiguation)\"). [...] New Delhi (/ˈ nj uː ˈ d ɛ.l i/ⓘ;( _\\\\\\\\_\\\\\\\\\\\\\\\\_Naī Dillī\\\\\\\\\\\\\\\\_\\\\\\\\__, pronounced( \"Help:IPA/Hindi and Urdu\")) is the capital of India and a part of the National Capital Territory of Delhi (NCT). New Delhi is the seat of all three branches of the Government of India, hosting the Rashtrapati Bhavan, Sansad Bhavan, and the Supreme Court. New Delhi is a municipality within the NCT, administered by the New Delhi Municipal Council (NDMC), which covers mostly Lutyens\\\\\\' Delhi and a few adjacent areas. The municipal [...] a Hindu Mandir  \\\\n   Image 30: Qila-i-Kuhna Mosque inside Old Fort, a mosque Qila-i-Kuhna Mosque inside Old Fort, \\\\n\\\\na mosque \\\\n\\\\nGovernment\\\\n----------\\\\n\\\\nMain articles: New Delhi Municipal Council, Government of Delhi, and Delhi Police\\\\n\\\\nThe national capital of India, New Delhi is jointly administered by both the Central Government of India and the local Government of Delhi, it is also the capital of the National Capital Territory (NCT) of Delhi.\\\\n\\\\nImage 31\\\\n\\\\nMunicipalities of Delhi\\\\n\\\\nImage 32\\', \\'score\\': 0.9108078}, {\\'title\\': \\'Capital of India - Definition, Meaning & Synonyms - Vocabulary.com\\', \\'url\\': \\'https://www.vocabulary.com/dictionary/capital%20of%20India\\', \\'content\\': \\'1.  noun\\\\n    \\\\n    the capital of India is a division of the old city of Delhi\\\\n    \\\\n    synonyms: Indian capital, New Delhi\\\\n    \\\\n    see moresee less\\\\n    \\\\n    example of:\\\\n    \\\\n    national capital\\\\n    \\\\n    the capital city of a nation\\\\n    \\\\n\\\\nCite this entry\\\\n\\\\nStyle:\\\\n\\\\nMLA\\\\n\\\\n   MLA\\\\n   APA\\\\n   Chicago\\\\n\\\\n\"Capital of India.\" _Vocabulary.com Dictionary,_ Vocabulary.com,  of India. Accessed 11 May. 2025.\\\\n\\\\nCopy citation\\', \\'score\\': 0.90810597}, {\\'title\\': \\'New Delhi | History, Population, Map, & Facts | Britannica\\', \\'url\\': \\'https://www.britannica.com/place/New-Delhi\\', \\'content\\': \\'Image 19: New Delhi, India\\\\n\\\\nNew Delhi, India(more)\\\\n\\\\nNew Delhi, national capital of India. It is situated in the north-central part of the country on the west bank of the Yamuna River, adjacent to and just south of Delhi city (Old Delhi) and within the Delhi national capital territory. [...] Delhi, city and national capital, and union territory, north-central India. The city of Delhi actually consists of two components: Old Delhi, in the north, the historic city; and New Delhi, in the south, since 1947 the capital of India, built in the first part of the 20th century as the capital of British India.\\\\n\\\\nImage 45: Rashtrapati Bhavan and the Jaipur Column [...] What is New Delhi?\\\\n\\\\nNew Delhi is the national capital of India.\\\\n\\\\n### \\\\n\\\\nWhere is New Delhi?\\\\n\\\\nNew Delhi is situated in the north-central part of India on the west bank of the Yamuna River, adjacent to and just south of Old Delhi, the historic centre of Delhi, and within the Delhi national capital territory.\\\\n\\\\n### \\\\n\\\\nWhen was New Delhi founded?\\', \\'score\\': 0.8449346}]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_mapping[\"search\"].invoke({\"query\":\"What is the capital of india?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f94e4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Result for current GDP of India is: \\n[{\\'title\\': \\'India Becoming An Economic Powerhouse - PIB\\', \\'url\\': \\'https://www.pib.gov.in/PressNoteDetails.aspx?NoteId=154660\\', \\'content\\': \\'India’s GDP has witnessed a remarkable transformation over the past decade. At current prices, GDP has increased from ₹106.57 lakh crore in 2014–15 to an estimated ₹331.03 lakh crore in 2024–25, an approximate threefold rise in just ten years. In 2024–25 alone, nominal GDP grew by 9.9% over the previous year, while real GDP (at constant prices) increased by 6.5%, reflecting sustained economic momentum. This steep growth reflects the country’s expanding economic base and rising income levels. [...] India, the world’s fourth-largest economy, has emerged as the fastest-growing major economy and is on track to become the world’s third-largest economy with a projected GDP of $7.3 trillion by 2030. India is projected to be world’s fastest growing major economy (6.3% to 6.8% in 2025-26). This transformation is the result of a decade of decisive governance, visionary reforms, and global engagement under Prime Minister Narendra Modi. Driven by robust domestic demand, a dynamic demographic [...] This growth was supported by a marginal increase in merchandise exports, which stood at US$ 437.42 billion in FY 2024–25 compared to US$ 437.07 billion in the previous year, reflecting stability in goods-based trade. Over the decade, merchandise exports rose from US$ 310 billion in 2013–14 to US$ 437.42 billion in 2024–25, marking a 39% increase, driven by sectors such as engineering goods, petroleum products, and electronics.\\', \\'score\\': 0.8834878}, {\\'title\\': \\'World GDP Ranking 2025 List - ClearTax\\', \\'url\\': \\'https://cleartax.in/s/world-gdp-ranking-list\\', \\'content\\': \"India is currently ranked as the 4th largest economy globally in 2025 as of July 2025, overtaking Japan to secure the 4th position among the world\\'s top 10 largest economies, with a nominal GDP of $4.19 trillion in 2025. Moreover, the IMF forecasts that by 2028, India will overtake Germany to become the 3rd largest economy worldwide. [...] As per IMF projections, India\\'s GDP grow is at 6.2% in 2024-25 and 2025-26.With an estimated real GDP of Rs. 187.95 lakh crore in 2024-25, against the real GDP of Rs. 176.51 in 2023-24 generated by a population of over 1 billion, India is among the highest population-based economies in the world. India’s nominal GDP has grown 105% in just a decade, which means that it has more than doubled from 2014 to 2025. [...] In 2025, India has become a $4 trillion economy. As per IMF Data, India is the 4th largest economy in the world in the year 2025 on par with Japan. Today,India’s leading economic contributors are traditional and modern agriculture, technology services, the handicraft industry, and business outsourcing.\", \\'score\\': 0.8539252}, {\\'title\\': \\'India GDP - Trading Economics\\', \\'url\\': \\'https://tradingeconomics.com/india/gdp\\', \\'content\\': \\'##### Members\\\\n\\\\n##### \\\\n\\\\n# India GDP\\\\n\\\\n## The Gross Domestic Product (GDP) in India was worth 3912.69 billion US dollars in 2024, according to official data from the World Bank. The GDP value of India represents 3.69 percent of the world economy. source: World Bank [...] ## GDP in India averaged 834.50 USD Billion from 1960 until 2024, reaching an all time high of 3912.69 USD Billion in 2024 and a record low of 37.03 USD Billion in 1960. This page provides the latest reported value for - India GDP - plus previous releases, historical high and low, short-term forecast and long-term prediction, economic calendar, survey consensus and news. India GDP - values, historical data and charts - was last updated on August of 2025. [...] | Related | Last | Previous | Unit | Reference |\\\\n| --- | --- | --- | --- | --- |\\\\n| Fiscal Year GDP Growth | 6.50 | 9.20 | percent | Mar 2025 |\\\\n| GDP | 3912.69 | 3638.49 | USD Billion | Dec 2024 |\\\\n| GDP Growth Rate YoY | 7.40 | 6.40 | percent | Mar 2025 |\\\\n| GDP Growth Rate | 2.00 | 1.90 | percent | Mar 2025 |\\\\n| GDP per Capita | 2396.71 | 2270.91 | USD | Dec 2024 |\\\\n| GDP per Capita PPP | 9817.07 | 9301.76 | USD | Dec 2024 |\\', \\'score\\': 0.8455478}, {\\'title\\': \\'India Fiscal Year GDP Growth - Trading Economics\\', \\'url\\': \\'https://tradingeconomics.com/india/full-year-gdp-growth\\', \\'content\\': \\'| Related | Last | Previous | Unit | Reference |\\\\n| --- | --- | --- | --- | --- |\\\\n| Fiscal Year GDP Growth | 6.50 | 9.20 | percent | Mar 2025 |\\\\n| GDP | 3912.69 | 3638.49 | USD Billion | Dec 2024 |\\\\n| GDP Growth Rate YoY | 7.40 | 6.40 | percent | Mar 2025 |\\\\n| GDP Constant Prices | 51351.63 | 47265.42 | INR Billion | Mar 2025 |\\\\n| GDP from Agriculture | 6773.89 | 7757.32 | INR Billion | Mar 2025 |\\\\n| GDP from Construction | 4636.41 | 3899.90 | INR Billion | Mar 2025 | [...] | GDP from Manufacturing | 8299.55 | 6960.49 | INR Billion | Mar 2025 |\\\\n| GDP from Mining | 1013.49 | 824.88 | INR Billion | Mar 2025 |\\\\n| GDP from Public Administration | 5623.82 | 5544.70 | INR Billion | Mar 2025 |\\\\n| GDP from Utilities | 1000.44 | 963.01 | INR Billion | Mar 2025 |\\\\n| GDP Growth Rate | 2.00 | 1.90 | percent | Mar 2025 |\\\\n| Gross Fixed Capital Formation | 17411.50 | 14991.34 | INR Billion | Mar 2025 | [...] ## Full Year GDP Growth in India decreased to 6.50 percent in 2025 from 9.20 percent in 2024. Full Year GDP Growth in India averaged 6.42 percent from 2006 until 2025, reaching an all time high of 9.70 percent in 2022 and a record low of -5.80 percent in 2021. This page includes a chart with historical data for India Full Year GDP Growth. India Fiscal Year GDP Growth - data, historical chart, forecasts and calendar of releases - was last updated on August of 2025.\\', \\'score\\': 0.79901963}, {\\'title\\': \"India\\'s Economic Juggernaut On Way To Becoming The 3rd Largest ...\", \\'url\\': \\'https://www.forbes.com/sites/sarwantsingh/2025/07/14/indias-economic-juggernaut-on-way-to-becoming-the-3rd-largest-economy/\\', \\'content\\': \"Despite external pressures, India\\'s economy continues to demonstrate impressive resilience. In nominal terms, the country is projected to become a USD 30 trillion economy by 2047, targeting an average nominal GDP growth rate of 9%–10% per year. India’s gross savings to GDP ratio, too, is expected to improve, projected to reach 48% by 2036–37 under a linear trend scenario, supporting strong investment-led growth. Though the country faces some concerns regarding the current account balance and [...] India is already on the path to economic greatness, having surpassed Japan recently to become the 4th largest economy in 2025.And that’s just the beginning! By 2028, India is also expected to become the world’s third-largest economy, moving ahead of Germany. India is aiming to add about USD 1 trillion to its GDP every 12 to 18 months over the next decade, targeting a CAGR of 9% nominal GDP growth rate from 2025 to 2047. While this is undoubtedly ambitious, India’s strong macroeconomic [...] Maharashtra, Gujarat, and Tamil Nadu are on track to reach a GDP of USD 1 trillion each by 2035—collectively matching the combined economic might of the United Arab Emirates, Sweden, and Belgium, and highlighting their role as the engines of India’s economic progress. Rapid expansion, urban development, and a focus on high-value industries have transformed these states into manufacturing powerhouses and financial centers, helping India gain a competitive edge and avoiding over-reliance on any\", \\'score\\': 0.7171114}]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_mapping[result.tool_calls[0][\"name\"]].invoke(result.tool_calls[0][\"args\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9a270",
   "metadata": {},
   "source": [
    "#### Human In Loop Use Case 1: Taking Permission and Proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c5017",
   "metadata": {},
   "source": [
    "![alt text](428a6a26-e9b8-4125-b8a9-aab14b692d23.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb95c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Sequence, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, START,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for the agent.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage],operator.add]\n",
    "\n",
    "# LLM Calling Function\n",
    "def invoke_model(state:AgentState):\n",
    "    messages=state[\"messages\"]\n",
    "    question=messages[-1]\n",
    "    response=llm_with_tools.invoke(question)\n",
    "    return {\"messages\":[response]}\n",
    "\n",
    "# Router Function\n",
    "def router(state:AgentState):\n",
    "    tool_calls=state[\"messages\"][-1].tool_calls\n",
    "    if len(tool_calls)>0:\n",
    "        return \"tool\" #key name\n",
    "    else:\n",
    "        return \"end\" #key name\n",
    "    \n",
    "# Tool Calling Function: Responsible for Asking User for approval to use a tool\n",
    "def invoke_tool(state:AgentState):\n",
    "    tool_details=state[\"messages\"][-1].tool_calls\n",
    "    \n",
    "    if tool_details is None:\n",
    "        return Exception(\"No tool calls found in the last message.\")\n",
    "    \n",
    "    print(f\"Seleted tool: {tool_details[0]['name']}\")\n",
    "    \n",
    "    if tool_details[0][\"name\"]==\"search\":\n",
    "        response=input(prompt=f\"[yes/no] do you want to continue with this expensive web search\")\n",
    "        if response.lower()==\"no\":\n",
    "            print(\"web search discarded by the user. exiting gracefully\")\n",
    "            raise Exception(\"Web search discarded by the user.\")\n",
    "            \n",
    "    \n",
    "    response=tool_mapping[tool_details[0][\"name\"]].invoke(tool_details[0][\"args\"])\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd6aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow\n",
    "\n",
    "graph=StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"ai_assistant\", invoke_model)\n",
    "\n",
    "# eariler we were using the ToolNode(from the prebuilt library) from list of tool\n",
    "# but now we have created tool_invoke (custom funtion)\n",
    "# why we are doing it? -> as a user if we want to take a authority to which i need to give permission for execution\n",
    "\n",
    "graph.add_node(\"tool\", invoke_tool)\n",
    "\n",
    "graph.add_conditional_edges(\"ai_assistant\",\n",
    "                            router,\n",
    "                            {\n",
    "                                \"tool\":\"tool\", ##with the key tool which value is associated <tool>\n",
    "                                \"end\":END\n",
    "                            }\n",
    "                            )\n",
    "\n",
    "graph.add_edge(\"tool\", END)\n",
    "\n",
    "graph.set_entry_point(\"ai_assistant\")\n",
    "\n",
    "app=graph.compile()\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e7940",
   "metadata": {},
   "source": [
    "### Human In Loop Use Case 2: INTERRUPT BEFORE (Take User Input and Integrate in Workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06bf5c",
   "metadata": {},
   "source": [
    "![alt text](18bf5d8f-0193-4d25-ae43-8980b58d2220.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a574c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "094e010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "llm_with_tools=llm.bind_tools(tools)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "def ai_assistant(state: AgentState):\n",
    "    response=llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ec842d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29f530697f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node=ToolNode(tools)\n",
    "memory=MemorySaver()\n",
    "\n",
    "# Workflow\n",
    "\n",
    "graph_builder=StateGraph(AgentState)\n",
    "graph_builder.add_node(\"ai_assistant\", ai_assistant)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_edge(START,\"ai_assistant\")\n",
    "graph_builder.add_conditional_edges(\"ai_assistant\",\n",
    "                                    tools_condition,\n",
    "                                    )\n",
    "graph_builder.add_edge(\"tools\", \"ai_assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "589142f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing the concept of INTERRUPT BEFORE - This stops the flow before the prescribed state\n",
    "\n",
    "\n",
    "app2=graph_builder.compile(checkpointer=memory,interrupt_before=[\"tools\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587ac16",
   "metadata": {},
   "source": [
    "#### Integrating Asking User For approval before invoking any tool in the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df1f538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current gdp of the china?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of China. I need to figure out the best way to get this information. I remember that I have access to a tool called \"search\" which can look up information on the web. \\n\\nFirst, I should use the \"search\" tool with the query \"current GDP of China\" to find the most recent data. Once I get the results, I can extract the specific GDP figure and present it to the user. \\n\\nI should make sure the search query is clear and specific to get accurate results. After obtaining the data, I\\'ll format the response to be helpful and informative for the user.\\n', 'tool_calls': [{'id': 'rrnm07r1m', 'function': {'arguments': '{\"query\":\"current GDP of China\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 176, 'total_tokens': 337, 'completion_time': 0.72368371, 'prompt_time': 0.024791377, 'queue_time': 0.216469002, 'total_time': 0.748475087}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--200a8458-5fde-4f05-afde-88fa9dc4b47b-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of China'}, 'id': 'rrnm07r1m', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 161, 'total_tokens': 337})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
    "response = app2.invoke({\"messages\":[HumanMessage(\"What is the current gdp of the china?\")]}, config=config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0071b020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='What is the current gdp of the china?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of China. I need to figure out the best way to get this information. I remember that I have access to a tool called \"search\" which can look up information on the web. \\n\\nFirst, I should use the \"search\" tool with the query \"current GDP of China\" to find the most recent data. Once I get the results, I can extract the specific GDP figure and present it to the user. \\n\\nI should make sure the search query is clear and specific to get accurate results. After obtaining the data, I\\'ll format the response to be helpful and informative for the user.\\n', 'tool_calls': [{'id': 'rrnm07r1m', 'function': {'arguments': '{\"query\":\"current GDP of China\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 176, 'total_tokens': 337, 'completion_time': 0.72368371, 'prompt_time': 0.024791377, 'queue_time': 0.216469002, 'total_time': 0.748475087}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--200a8458-5fde-4f05-afde-88fa9dc4b47b-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of China'}, 'id': 'rrnm07r1m', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 161, 'total_tokens': 337})]}, next=('tools',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f071612-7df2-66d5-8001-cc1e21838beb'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}, 'thread_id': '1'}, created_at='2025-08-04T18:30:54.318751+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f071612-7347-6301-8000-be3aad9eae9d'}}, tasks=(PregelTask(id='8b7a067a-634d-5c3e-fb9f-06b73187395d', name='tools', path=('__pregel_pull', 'tools'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get State - Captures the State\n",
    "\n",
    "snapshot=app2.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5d0ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next - Tells what is Next in the state\n",
    "\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a03983a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'args': {'query': 'current GDP of China'},\n",
       "  'id': 'rrnm07r1m',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Tool Details\n",
    "\n",
    "last_message = snapshot.values[\"messages\"][-1]\n",
    "tool_details = last_message.tool_calls\n",
    "\n",
    "tool_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54375330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is the current gdp of the china?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of China. I need to figure out the best way to get this information. I remember that I have access to a tool called \"search\" which can look up information on the web. \\n\\nFirst, I should use the \"search\" tool with the query \"current GDP of China\" to find the most recent data. Once I get the results, I can extract the specific GDP figure and present it to the user. \\n\\nI should make sure the search query is clear and specific to get accurate results. After obtaining the data, I\\'ll format the response to be helpful and informative for the user.\\n', 'tool_calls': [{'id': 'rrnm07r1m', 'function': {'arguments': '{\"query\":\"current GDP of China\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 176, 'total_tokens': 337, 'completion_time': 0.72368371, 'prompt_time': 0.024791377, 'queue_time': 0.216469002, 'total_time': 0.748475087}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--200a8458-5fde-4f05-afde-88fa9dc4b47b-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of China'}, 'id': 'rrnm07r1m', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 161, 'total_tokens': 337}), ToolMessage(content='Result for current GDP of China is: \\n[{\\'title\\': \\'China GDP - Trading Economics\\', \\'url\\': \\'https://tradingeconomics.com/china/gdp\\', \\'content\\': \\'##### Members\\\\n\\\\n##### \\\\n\\\\n# China GDP\\\\n\\\\n## The Gross Domestic Product (GDP) in China was worth 18743.80 billion US dollars in 2024, according to official data from the World Bank. The GDP value of China represents 17.65 percent of the world economy. source: World Bank [...] ## GDP in China averaged 3590.13 USD Billion from 1960 until 2024, reaching an all time high of 18743.80 USD Billion in 2024 and a record low of 47.31 USD Billion in 1962. This page provides - China GDP - actual values, historical data, forecast, chart, statistics, economic calendar and news. China GDP - values, historical data and charts - was last updated on August of 2025. [...] ### GDP in China is expected to reach 19681.00 USD Billion by the end of 2025, according to Trading Economics global macro models and analysts expectations. In the long-term, the China GDP is projected to trend around 20626.00 USD Billion in 2026 and 21574.00 USD Billion in 2027, according to our econometric models.\\', \\'score\\': 0.8524574}, {\\'title\\': \\'China GDP Annual Growth Rate - Trading Economics\\', \\'url\\': \\'https://tradingeconomics.com/china/gdp-growth-annual\\', \\'content\\': \\'## The Gross Domestic Product (GDP) in China expanded 5.20 percent in the second quarter of 2025 over the same quarter of the previous year. GDP Annual Growth Rate in China averaged 8.76 percent from 1989 until 2025, reaching an all time high of 18.90 percent in the first quarter of 2021 and a record low of -6.80 percent in the first quarter of 2020. This page provides - China GDP Annual Growth Rate - actual values, historical data, forecast, chart, statistics, economic calendar and news. China [...] | GDP from Manufacturing | 202550.30 | 98344.50 | CNY Hundred Million | Jun 2025 |\\\\n| GDP from Services | 390313.80 | 195142.30 | CNY Hundred Million | Jun 2025 |\\\\n| GDP from Transport | 29512.80 | 13892.50 | CNY Hundred Million | Jun 2025 |\\\\n| GDP Growth Rate | 1.10 | 1.20 | percent | Jun 2025 |\\\\n| Gross Fixed Capital Formation | 537875.60 | 523590.30 | CNY Hundred Million | Dec 2024 |\\\\n| Gross National Income | 1339672.00 | 1283680.30 | CNY Hundred Million | Dec 2024 | [...] | Related | Last | Previous | Unit | Reference |\\\\n| --- | --- | --- | --- | --- |\\\\n| Full Year GDP Growth | 5.00 | 5.40 | percent | Dec 2024 |\\\\n| GDP Growth Rate YoY | 5.20 | 5.40 | percent | Jun 2025 |\\\\n| GDP Constant Prices | 630101.00 | 306612.20 | CNY Hundred Million | Jun 2025 |\\\\n| GDP from Agriculture | 31171.80 | 11712.80 | CNY Hundred Million | Jun 2025 |\\\\n| GDP from Construction | 38210.60 | 14429.90 | CNY Hundred Million | Jun 2025 |\\', \\'score\\': 0.78963995}, {\\'title\\': \"How to Predict China\\'s Economic Performance for 2025: A Sectoral ...\", \\'url\\': \\'https://carnegieendowment.org/posts/2025/05/how-to-predict-chinas-economic-performance-for-2025?lang=en\\', \\'content\\': \\'Already in early 2025, analysts have revised their estimates several times. At the beginning of the year, most banks expected that China’s GDP growth in 2025 would come in well below the GDP growth target of 5 percent. But these expectations changed in late March after Chinese leadership made ambitious economic pronouncements during the annual Two Sessions governmental meetings in March. As the Wall Street Journal reported, the banks HSBC, ANZ, and Citi upgraded their forecasts for China’s GDP [...] Barring a disaster, in which case all predictions will be off, China will almost certainly achieve its GDP growth target in 2025, which means that predictions by all the global financial institutions will converge to 4.8–5.0 percent by the fourth quarter of 2025. Lower predicted growth rates earlier in the year, in other words, are mostly meaningless as predictions. [...] The point is that GDP growth means something fundamentally different in China than in most countries. In the West, it is an output—a measure of economic activity that emerges from countless decentralized decisions—and so it makes sense to evaluate growth prospects continuously over the year and to change them as underlying conditions change. In China, GDP growth is an input—a number that is decided early in the year and then achieved through whatever intervention is necessary. For that reason,\\', \\'score\\': 0.6072213}, {\\'title\\': \\'China Calendar\\', \\'url\\': \\'https://tradingeconomics.com/china/calendar\\', \\'content\\': \\'| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| Thursday August 07 2025 | | | Actual | Previous | Consensus | Forecast |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| 03:00 AM | |  |  | | --- | --- | |  | CN | | Balance of Trade JUL |  | $114.77B | $103.4B | $117.3B |  |  |\\\\n| 03:00 AM | |  |  | | --- | --- | |  | CN | | Exports YoY JUL |  | 5.8% | 5.0% | 5.1% |  |  |\\\\n| 03:00 AM | |  |  | | --- | --- | |  | CN | | Imports YoY JUL |  | 1.1% | -1.0% | -1.3% |  |  | [...] |  | |  |  | | --- | --- | |  | CN | | Foreign Exchange Reserves JUL |  | $3.317T |  | $3.32T |  |  |\\\\n| Friday August 08 2025 | | | Actual | Previous | Consensus | Forecast |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| Friday August 08 2025 | | | Actual | Previous | Consensus | Forecast |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| 09:00 AM | |  |  | | --- | --- | |  | CN | | Current Account Prel Q2 |  | $165.4B |  | $85.0B |  |  | [...] | 01:30 AM | |  |  | | --- | --- | |  | CN | | PPI YoY JUL |  | -3.6% | -3.2% | -3.4% |  |  |\\\\n| Wednesday August 13 2025 | | | Actual | Previous | Consensus | Forecast |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n| Wednesday August 13 2025 | | | Actual | Previous | Consensus | Forecast |  |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n|  | |  |  | | --- | --- | |  | CN | | Vehicle Sales YoY JUL |  | 13.8% |  | 15.0% |  |  |\\', \\'score\\': 0.46424627}, {\\'title\\': \\'China posts better-than-expected Q2 growth in face of Trump tariffs\\', \\'url\\': \\'https://www.cnn.com/2025/07/14/business/china-gdp-q2-economy-intl-hnk\\', \\'content\\': \\'The GDP growth in the second quarter was a slowdown from a 5.4% expansion in the first three months of the year. Together, GDP growth for the first half of the year compared to the same period last year stood at 5.3%, according to the NBS.\\\\n\\\\nSheng Laiyun, deputy commissioner of the NBS, said the growth in the first half of the year was achieved “under the challenging circumstances of rapidly shifting international dynamics and significantly increased external pressure since the second quarter.” [...] Gross domestic product (GDP) expanded 5.2% in the second quarter from the same period a year earlier, according to the National Bureau of Statistics (NBS) at a press conference on Tuesday. That was higher than the average prediction of 5.1%, based on a poll of 40 economists surveyed by Reuters on Friday. [...] “We are also keenly aware that the external environment remains complex and volatile, internal structural problems have yet to be fundamentally resolved, and the foundation of economic performance still needs to be further strengthened,” he said.\\\\n\\\\nChina’s economy remains under mounting external and internal pressure to meet its ambitious target of “around 5%” growth set for this year, a goal economists believe will be tough to achieve without further policy support.\\', \\'score\\': 0.44087905}]', name='search', tool_call_id='rrnm07r1m'), AIMessage(content=\"The current GDP of China, as of the latest data, is approximately **$18,743.80 billion USD** (as of 2024). This figure represents about **17.65% of the world economy**. Additionally, China's GDP is expected to reach **$19,681 billion USD** by the end of 2025, according to projections from Trading Economics. For more detailed and up-to-date information, you can refer to sources like Trading Economics or the National Bureau of Statistics of China.\", additional_kwargs={'reasoning_content': 'Okay, so the user is asking about the current GDP of China. I remember that GDP stands for Gross Domestic Product, which is a measure of a country\\'s economic performance. To find the most accurate and up-to-date information, I should use the tools provided.\\n\\nFirst, I think about which tool would be best for this. There\\'s a \"search\" tool that can look up information on the web. That seems perfect because it can fetch the latest data from reliable sources.\\n\\nI need to format the function call correctly. The function name is \"search\" and it requires a \"query\" parameter. So, I\\'ll set the query to \"current GDP of China\" to get the most relevant results.\\n\\nAfter making the call, I receive a list of results. The first result from Trading Economics mentions that China\\'s GDP was $18,743.80 billion in 2024 and is expected to reach $19,681 billion by the end of 2025. This seems like the most accurate and recent data.\\n\\nI should present this information clearly to the user, highlighting the current GDP and the projected growth. It\\'s also good to mention the source to ensure credibility.\\n'}, response_metadata={'token_usage': {'completion_tokens': 345, 'prompt_tokens': 2313, 'total_tokens': 2658, 'completion_time': 1.4311836740000001, 'prompt_time': 0.216580611, 'queue_time': 0.19413838799999997, 'total_time': 1.647764285}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--f3a0e6da-b7ed-43f5-8f8d-5316dc15ecfb-0', usage_metadata={'input_tokens': 2313, 'output_tokens': 345, 'total_tokens': 2658})]}\n"
     ]
    }
   ],
   "source": [
    "# Handling the Human in loop now, asking user what to do and getting approval\n",
    "\n",
    "if tool_details[0][\"name\"]== \"search\":\n",
    "    user_input = input(prompt=f\"[yes/no] do you want to continue with {tool_details[0]['name']}?\").lower()\n",
    "    if user_input==\"no\":\n",
    "        print(\"web tool discarded\")\n",
    "        raise Exception(\"Web tool discarded by the user.\")\n",
    "    else:\n",
    "        response=app2.invoke(None,config) # None continues the state(removes interruption)\n",
    "        print(response)\n",
    "else:\n",
    "    response=app2.invoke(None,config)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd33e30",
   "metadata": {},
   "source": [
    "#### Adding Human Input in the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa052d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current gdp of the japan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of Japan. I need to figure out how to get that information. I remember that I have access to a tool called \"search\" which can look up information on the web. So, I should use that tool to find the latest GDP data for Japan.\\n\\nFirst, I\\'ll call the search function with the query \"current GDP of Japan\". That should bring up the most recent data. Once I get the results, I\\'ll extract the GDP figure and present it to the user. I need to make sure the information is up-to-date and accurate, so I\\'ll rely on credible sources from the search results.\\n\\nI should also consider the format of the response. The user probably expects a clear and concise answer, so I\\'ll present the GDP number along with the year or the most recent quarter available. If there are multiple sources, I might take an average or note any discrepancies, but I\\'ll prioritize the most authoritative source, like official statistics from Japan\\'s government or reputable financial institutions.\\n\\nAdditionally, I might want to mention the factors contributing to Japan\\'s current GDP, such as economic growth, inflation, or significant events impacting the economy. This could provide a more comprehensive understanding for the user. However, since the user specifically asked for the GDP figure, I\\'ll focus on that unless they request more detailed information.\\n\\nI should also be cautious about the currency. GDP is usually reported in local currency, which is the Japanese Yen, but sometimes it\\'s also presented in USD. I\\'ll clarify which one I\\'m using to avoid confusion. If the user needs it in a different currency, I can adjust accordingly, but I\\'ll stick with the most commonly used one unless specified otherwise.\\n\\nLastly, I\\'ll make sure to present the information in a clear and friendly manner, avoiding any technical jargon that might confuse the user. The goal is to provide a helpful and accurate response that meets their needs effectively.\\n', 'tool_calls': [{'id': '8b19zpde8', 'function': {'arguments': '{\"query\":\"current GDP of Japan\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 420, 'prompt_tokens': 176, 'total_tokens': 596, 'completion_time': 2.192861229, 'prompt_time': 0.02734519, 'queue_time': 0.19243301100000001, 'total_time': 2.220206419}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ba1cdfef-457f-4bc4-966d-1e6264b83023-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of Japan'}, 'id': '8b19zpde8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 420, 'total_tokens': 596})]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"3\"}}\n",
    "response=app2.invoke({\"messages\":[HumanMessage(\"What is the current gdp of the japan?\")]},config=config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c01d7a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot=app2.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97bc2980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'args': {'query': 'current GDP of Japan'},\n",
       "  'id': '8b19zpde8',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_message=snapshot.values[\"messages\"][-1]\n",
    "last_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a5dcc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8b19zpde8'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_id=last_message.tool_calls[0][\"id\"]\n",
    "tool_call_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57fb5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding User Input into the flow using ToolMessage\n",
    "\n",
    "new_message=[\n",
    "    ToolMessage(content=\"according to the latest data 4.1 trillion USD\", tool_call_id=tool_call_id), # This will give the User Input here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92209707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '3',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f071654-532e-6511-8002-cac3fcb6f37b'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating the state by apending this new message\n",
    "\n",
    "app2.update_state(config,\n",
    "                  {\n",
    "                      \"messages\": new_message\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af0d59b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='according to the latest data 4.1 trillion USD', tool_call_id='8b19zpde8')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app2.get_state(config).values[\"messages\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83a8c37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current gdp of the japan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of Japan. I need to figure out how to get that information. I remember that I have access to a tool called \"search\" which can look up information on the web. So, I should use that tool to find the latest GDP data for Japan.\\n\\nFirst, I\\'ll call the search function with the query \"current GDP of Japan\". That should bring up the most recent data. Once I get the results, I\\'ll extract the GDP figure and present it to the user. I need to make sure the information is up-to-date and accurate, so I\\'ll rely on credible sources from the search results.\\n\\nI should also consider the format of the response. The user probably expects a clear and concise answer, so I\\'ll present the GDP number along with the year or the most recent quarter available. If there are multiple sources, I might take an average or note any discrepancies, but I\\'ll prioritize the most authoritative source, like official statistics from Japan\\'s government or reputable financial institutions.\\n\\nAdditionally, I might want to mention the factors contributing to Japan\\'s current GDP, such as economic growth, inflation, or significant events impacting the economy. This could provide a more comprehensive understanding for the user. However, since the user specifically asked for the GDP figure, I\\'ll focus on that unless they request more detailed information.\\n\\nI should also be cautious about the currency. GDP is usually reported in local currency, which is the Japanese Yen, but sometimes it\\'s also presented in USD. I\\'ll clarify which one I\\'m using to avoid confusion. If the user needs it in a different currency, I can adjust accordingly, but I\\'ll stick with the most commonly used one unless specified otherwise.\\n\\nLastly, I\\'ll make sure to present the information in a clear and friendly manner, avoiding any technical jargon that might confuse the user. The goal is to provide a helpful and accurate response that meets their needs effectively.\\n', 'tool_calls': [{'id': '8b19zpde8', 'function': {'arguments': '{\"query\":\"current GDP of Japan\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 420, 'prompt_tokens': 176, 'total_tokens': 596, 'completion_time': 2.192861229, 'prompt_time': 0.02734519, 'queue_time': 0.19243301100000001, 'total_time': 2.220206419}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ba1cdfef-457f-4bc4-966d-1e6264b83023-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of Japan'}, 'id': '8b19zpde8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 420, 'total_tokens': 596}),\n",
       "  ToolMessage(content='according to the latest data 4.1 trillion USD', tool_call_id='8b19zpde8')]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app2.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b2c29af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current gdp of the japan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of Japan. I need to figure out how to get that information. I remember that I have access to a tool called \"search\" which can look up information on the web. So, I should use that tool to find the latest GDP data for Japan.\\n\\nFirst, I\\'ll call the search function with the query \"current GDP of Japan\". That should bring up the most recent data. Once I get the results, I\\'ll extract the GDP figure and present it to the user. I need to make sure the information is up-to-date and accurate, so I\\'ll rely on credible sources from the search results.\\n\\nI should also consider the format of the response. The user probably expects a clear and concise answer, so I\\'ll present the GDP number along with the year or the most recent quarter available. If there are multiple sources, I might take an average or note any discrepancies, but I\\'ll prioritize the most authoritative source, like official statistics from Japan\\'s government or reputable financial institutions.\\n\\nAdditionally, I might want to mention the factors contributing to Japan\\'s current GDP, such as economic growth, inflation, or significant events impacting the economy. This could provide a more comprehensive understanding for the user. However, since the user specifically asked for the GDP figure, I\\'ll focus on that unless they request more detailed information.\\n\\nI should also be cautious about the currency. GDP is usually reported in local currency, which is the Japanese Yen, but sometimes it\\'s also presented in USD. I\\'ll clarify which one I\\'m using to avoid confusion. If the user needs it in a different currency, I can adjust accordingly, but I\\'ll stick with the most commonly used one unless specified otherwise.\\n\\nLastly, I\\'ll make sure to present the information in a clear and friendly manner, avoiding any technical jargon that might confuse the user. The goal is to provide a helpful and accurate response that meets their needs effectively.\\n', 'tool_calls': [{'id': '8b19zpde8', 'function': {'arguments': '{\"query\":\"current GDP of Japan\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 420, 'prompt_tokens': 176, 'total_tokens': 596, 'completion_time': 2.192861229, 'prompt_time': 0.02734519, 'queue_time': 0.19243301100000001, 'total_time': 2.220206419}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ba1cdfef-457f-4bc4-966d-1e6264b83023-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of Japan'}, 'id': '8b19zpde8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 420, 'total_tokens': 596}),\n",
       "  ToolMessage(content='according to the latest data 4.1 trillion USD', tool_call_id='8b19zpde8'),\n",
       "  HumanMessage(content='What is the current gdp of the japan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': \"Alright, the user is asking for the current GDP of Japan again. I remember they asked the same question before, and I used the search tool to find the answer. Last time, the result was $4.1 trillion USD. I should check if that's still the most recent data. Maybe the GDP has changed slightly since then. I'll use the search tool once more to get the latest information. Hopefully, the data hasn't changed much, but it's better to confirm to provide the most accurate answer.\\n\", 'tool_calls': [{'id': '8b19zpde8', 'function': {'arguments': '{\"query\":\"current GDP of Japan\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 249, 'total_tokens': 384, 'completion_time': 0.501206345, 'prompt_time': 0.03115643, 'queue_time': 0.192831588, 'total_time': 0.532362775}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0c3307b9-335a-4b43-a658-3619d04448a6-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of Japan'}, 'id': '8b19zpde8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 249, 'output_tokens': 135, 'total_tokens': 384})]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Until the above We have integrated the User Message into the flow\n",
    "\n",
    "app2.invoke({\"messages\":[HumanMessage(\"What is the current gdp of the japan?\")]},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a5a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the current gdp of the japan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking for the current GDP of Japan. I need to figure out how to get that information. I remember that I have access to a tool called \"search\" which can look up information on the web. So, I should use that tool to find the latest GDP data for Japan.\\n\\nFirst, I\\'ll call the search function with the query \"current GDP of Japan\". That should bring up the most recent data. Once I get the results, I\\'ll extract the GDP figure and present it to the user. I need to make sure the information is up-to-date and accurate, so I\\'ll rely on credible sources from the search results.\\n\\nI should also consider the format of the response. The user probably expects a clear and concise answer, so I\\'ll present the GDP number along with the year or the most recent quarter available. If there are multiple sources, I might take an average or note any discrepancies, but I\\'ll prioritize the most authoritative source, like official statistics from Japan\\'s government or reputable financial institutions.\\n\\nAdditionally, I might want to mention the factors contributing to Japan\\'s current GDP, such as economic growth, inflation, or significant events impacting the economy. This could provide a more comprehensive understanding for the user. However, since the user specifically asked for the GDP figure, I\\'ll focus on that unless they request more detailed information.\\n\\nI should also be cautious about the currency. GDP is usually reported in local currency, which is the Japanese Yen, but sometimes it\\'s also presented in USD. I\\'ll clarify which one I\\'m using to avoid confusion. If the user needs it in a different currency, I can adjust accordingly, but I\\'ll stick with the most commonly used one unless specified otherwise.\\n\\nLastly, I\\'ll make sure to present the information in a clear and friendly manner, avoiding any technical jargon that might confuse the user. The goal is to provide a helpful and accurate response that meets their needs effectively.\\n', 'tool_calls': [{'id': '8b19zpde8', 'function': {'arguments': '{\"query\":\"current GDP of Japan\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 420, 'prompt_tokens': 176, 'total_tokens': 596, 'completion_time': 2.192861229, 'prompt_time': 0.02734519, 'queue_time': 0.19243301100000001, 'total_time': 2.220206419}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ba1cdfef-457f-4bc4-966d-1e6264b83023-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of Japan'}, 'id': '8b19zpde8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 420, 'total_tokens': 596}),\n",
       "  ToolMessage(content='according to the latest data 4.1 trillion USD', tool_call_id='8b19zpde8'),\n",
       "  HumanMessage(content='What is the current gdp of the japan?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': \"Alright, the user is asking for the current GDP of Japan again. I remember they asked the same question before, and I used the search tool to find the answer. Last time, the result was $4.1 trillion USD. I should check if that's still the most recent data. Maybe the GDP has changed slightly since then. I'll use the search tool once more to get the latest information. Hopefully, the data hasn't changed much, but it's better to confirm to provide the most accurate answer.\\n\", 'tool_calls': [{'id': '8b19zpde8', 'function': {'arguments': '{\"query\":\"current GDP of Japan\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 249, 'total_tokens': 384, 'completion_time': 0.501206345, 'prompt_time': 0.03115643, 'queue_time': 0.192831588, 'total_time': 0.532362775}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0c3307b9-335a-4b43-a658-3619d04448a6-0', tool_calls=[{'name': 'search', 'args': {'query': 'current GDP of Japan'}, 'id': '8b19zpde8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 249, 'output_tokens': 135, 'total_tokens': 384}),\n",
       "  ToolMessage(content=\"Result for current GDP of Japan is: \\n[{'title': 'Japan GDP - Trading Economics', 'url': 'https://tradingeconomics.com/japan/gdp', 'content': '##### Members\\\\n\\\\n##### \\\\n\\\\n# Japan GDP\\\\n\\\\n## The Gross Domestic Product (GDP) in Japan was worth 4026.21 billion US dollars in 2024, according to official data from the World Bank. The GDP value of Japan represents 3.79 percent of the world economy. source: World Bank [...] | Components | Last | Unit | Reference |\\\\n| --- | --- | --- | --- |\\\\n| GDP from Agriculture | 5369.50 | JPY Billion | Dec 2023 |\\\\n| GDP from Construction | 28722.30 | JPY Billion | Dec 2023 |\\\\n| GDP from Manufacturing | 121800.40 | JPY Billion | Dec 2023 |\\\\n| GDP from Mining | 277.70 | JPY Billion | Dec 2023 |\\\\n| GDP from Public Administration | 27058.30 | JPY Billion | Dec 2023 |\\\\n| GDP from Services | 19914.40 | JPY Billion | Dec 2023 |\\\\n| GDP from Transport | 25797.00 | JPY Billion | Dec 2023 | [...] | Related | Last | Unit | Reference |\\\\n| --- | --- | --- | --- |\\\\n| GDP | 4026.21 | USD Billion | Dec 2024 |\\\\n| GDP per Capita | 37144.91 | USD | Dec 2024 |\\\\n| GDP per Capita PPP | 46097.43 | USD | Dec 2024 |\\\\n\\\\n|  | Actual | Previous | Highest | Lowest | Dates | Unit | Frequency |  |\\\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\\\n|  | 4026.21 | 4213.17 | 6272.36 | 47.42 | 1960 - 2024 | USD Billion | Yearly | Current USD |\\\\n\\\\n## Markets\\\\n\\\\n## GDP\\\\n\\\\n## Labour\\\\n\\\\n## Prices\\\\n\\\\n## Money\\\\n\\\\n## Trade', 'score': 0.8652358}, {'title': 'Japan GDP Growth Rate - Trading Economics', 'url': 'https://tradingeconomics.com/japan/gdp-growth', 'content': '| Related | Last | Previous | Unit | Reference |\\\\n| --- | --- | --- | --- | --- |\\\\n| Full Year GDP Growth | 0.10 | 1.90 | percent | Dec 2024 |\\\\n| GDP Annual Growth Rate | 1.70 | 1.30 | percent | Mar 2025 |\\\\n| GDP Constant Prices | 561055.80 | 562010.80 | JPY Billion | Mar 2025 |\\\\n| GDP from Agriculture | 5369.50 | 5312.10 | JPY Billion | Dec 2023 |\\\\n| GDP from Construction | 28722.30 | 28159.60 | JPY Billion | Dec 2023 |\\\\n| GDP from Manufacturing | 121800.40 | 120606.60 | JPY Billion | Dec 2023 | [...] | GDP from Mining | 277.70 | 295.90 | JPY Billion | Dec 2023 |\\\\n| GDP from Public Administration | 27058.30 | 27568.40 | JPY Billion | Dec 2023 |\\\\n| GDP from Services | 19914.40 | 19906.10 | JPY Billion | Dec 2023 |\\\\n| GDP from Transport | 25797.00 | 23680.70 | JPY Billion | Dec 2023 |\\\\n| GDP from Utilities | 17821.80 | 17069.70 | JPY Billion | Dec 2023 |\\\\n| GDP Growth Annualized | -0.20 | 2.40 | percent | Mar 2025 |\\\\n| GDP Growth Rate | 0.00 | 0.60 | percent | Mar 2025 | [...] ## The Gross Domestic Product (GDP) in Japan stagnated 0 percent in the first quarter of 2025 over the previous quarter. GDP Growth Rate in Japan averaged 0.42 percent from 1980 until 2025, reaching an all time high of 5.30 percent in the third quarter of 2020 and a record low of -7.60 percent in the second quarter of 2020. This page provides - Japan GDP Growth Rate - actual values, historical data, forecast, chart, statistics, economic calendar and news. Japan GDP Growth Rate - data,', 'score': 0.82220376}, {'title': 'GDP (current US$) - Japan - World Bank Open Data', 'url': 'https://data.worldbank.org/indicator/NY.GDP.MKTP.CD?locations=JP', 'content': 'The World Bank\\\\n\\\\nBrowse World Development Indicators byCountryorIndicator\\\\n\\\\n# GDP (current US$) - Japan\\\\n\\\\n1960 - 2024\\\\n\\\\n#### Download\\\\n\\\\nCSVXMLEXCEL\\\\n\\\\n#### DataBank\\\\n\\\\nExplore Our DataBank\\\\n\\\\n#### WDI Tables\\\\n\\\\nThematic data tables from WDI\\\\n\\\\n## Selected Countries and Economies\\\\n\\\\n## All Countries and Economies\\\\n\\\\nThe World Bank Working for a World Free of Poverty\\\\nWorld Bank Facebook\\\\nWorld Bank Twitter\\\\nWorld Bank Github\\\\nWorld Bank Linkedin [...] This site uses cookies to optimize functionality and give you the best possible experience. If you continue to navigate this website beyond this page, cookies will be placed on your browser. To learn more about cookies,  click here.', 'score': 0.56920683}, {'title': 'Japan economic outlook, July 2025 - Deloitte', 'url': 'https://www.deloitte.com/us/en/insights/topics/economy/asia-pacific/japan-economic-outlook.html', 'content': 'The reported numbers were also weighed down by elevated inflation. Nominal GDP grew at a 3.6% annualized rate from the previous quarter.4 If inflation comes back down to the Bank of Japan’s 2% target while maintaining this level of nominal growth, real GDP will rebound quite nicely. Unfortunately, inflation could prove to be sticky, and trade tensions with the United States could threaten a vital source of growth for the country. We expect real GDP to return to positive growth as some [...] Japan’s economy is struggling to find its footing amid high inflation and a global slowdown. Real gross domestic product fell an annualized 0.2% between the fourth quarter of 2024 and the first quarter of 2025.1 The main drags to growth came from the public sector and net exports. Imports had been weak in the previous quarter but rebounded at the start of the year, lowering the trade balance. [...] The central bank’s outlook for GDP has come down even more substantially to 0.5% from a previously forecasted 1.1%.18 The Bank of Japan is also expected to slow the pace of its cuts to government-bond purchases early next year in an effort to allow for additional support to the economy.19', 'score': 0.46832922}, {'title': 'Japan - World Economic Outlook (April 2025) - GDP, current prices', 'url': 'https://www.imf.org/external/datamapper/NGDPD@WEO/JPN', 'content': 'World Economic Outlook (April 2025) - GDP, current prices. GDP, current prices. Billions of US dollars. map, list, chart.', 'score': 0.46191534}]\", name='search', tool_call_id='8b19zpde8'),\n",
       "  AIMessage(content='The current GDP of Japan is **$4.1 trillion USD**, according to the latest data.', additional_kwargs={'reasoning_content': \"Alright, the user is asking for the current GDP of Japan. I remember that in the previous interaction, I used the search tool to find this information. Let me check the history to see what data I have.\\n\\nLooking back, the search results provided the GDP as $4.1 trillion USD. However, in the more recent tool output, I see that the GDP is stated as $4026.21 billion USD, which is approximately $4.026 trillion. This is from the World Bank data for December 2024.\\n\\nI should make sure to use the most up-to-date information. The user might be looking for the exact figure, so I'll present it clearly. Also, I should mention that this data is from the World Bank to give it credibility.\\n\\nI need to format the response neatly, maybe using bold for the GDP figure to make it stand out. Keeping it concise but informative would be best.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 1922, 'total_tokens': 2132, 'completion_time': 0.994927241, 'prompt_time': 0.184944815, 'queue_time': 0.193374134, 'total_time': 1.179872056}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--67d0e638-1a98-42f0-bafc-8e45bde7e868-0', usage_metadata={'input_tokens': 1922, 'output_tokens': 210, 'total_tokens': 2132})]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None makes the flow resume\n",
    "\n",
    "app2.invoke(None,config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
