{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ca49e5",
   "metadata": {},
   "source": [
    "# Multi Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5a5ab4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06f8e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f12e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6ab8861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 13, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bx27X5SrgHJ2xI2T83bHIfcGZWmqL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--cb2f9d82-1822-49c1-b9a7-56aa519dccd8-0', usage_metadata={'input_tokens': 13, 'output_tokens': 27, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi hello how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3b44b",
   "metadata": {},
   "source": [
    "### In Built Classes to connect agents, and create react agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15d24a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21cc514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646f6b6",
   "metadata": {},
   "source": [
    "### Example: Function using Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b5e88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number(state):\n",
    "    result = state[\"num1\"] + state[\"num2\"]\n",
    "    print(f\"Addition is {result}\")\n",
    "\n",
    "    return Command(goto=\"multiply\", update = {\"sum\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59e706a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"num1\": 10, \"num2\": 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85056b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition is 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 30}, goto='multiply')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_number(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a46cde",
   "metadata": {},
   "source": [
    "## Network/Collaborative Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae63606",
   "metadata": {},
   "source": [
    "### Creating one dummy multiagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dbfecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5331cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\"Ask multiplication agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c62093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_addition_expert():\n",
    "    \"\"\"Ask addition agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a3899be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n"
     ]
    }
   ],
   "source": [
    "llm_with_tool = llm.bind_tools([transfer_to_multiplication_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a004e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tool.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83de648e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f5f1ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7347b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tool.invoke(\"what is 2 * 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a2defc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3716e104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'transfer_to_multiplication_expert',\n",
       "  'args': {},\n",
       "  'id': 'call_Rf133QVKdrJDlxbf7mBFTfxl',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be84e70",
   "metadata": {},
   "source": [
    "### Creating StateGraph, and Using Command in the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17bf24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\"Ask multiplication agent for help\"\"\"\n",
    "    return\n",
    "\n",
    "@tool\n",
    "def transfer_to_addition_expert():\n",
    "    \"\"\"Ask addition agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a991767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an addition expert, you can ask the multiplication expert for help with multiplication.Always do your portion of calculation before the handoff.'},\n",
       " 'Can you tell me the addition of 2 and 2 ?']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "        \"You are an addition expert, you can ask the multiplication expert for help with multiplication.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + [\"Can you tell me the addition of 2 and 2 ?\"]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26720f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The addition of 2 and 2 is 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 83, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bx27Z7RPzgyED8jSpBoYLcKg6f9ju', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--eb1a8b13-4eed-438a-8cae-7f608fe7e578-0', usage_metadata={'input_tokens': 83, 'output_tokens': 13, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28a23da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langgraph.graph import MessagesState,StateGraph, START,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df477400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_expert(state: MessagesState)-> Command[Literal[\"multiplication_expert\", \"__end__\"]]:\n",
    "    SYSTEM_PROMPT = (\n",
    "        \"You are an addition expert, you can ask the multiplication expert for help with multiplication.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + state[\"messages\"]\n",
    "    llm_with_tool = llm.bind_tools([transfer_to_multiplication_expert])\n",
    "\n",
    "    ai_msg = llm_with_tool.invoke(messages)\n",
    "\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "\n",
    "        # Meta Info\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "\n",
    "        return Command(\n",
    "            goto = \"multiplication_expert\",\n",
    "            update = {\"messages\": [ai_msg, tool_msg]}\n",
    "        )\n",
    "\n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fc00d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_expert(state:MessagesState)-> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
    "    SYSTEM_PROMPT = (\n",
    "        \"You are an multiplication expert, you can ask the addition expert for help with addition.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}] + state[\"messages\"]\n",
    "    llm_with_tool = llm.bind_tools([transfer_to_addition_expert])\n",
    "\n",
    "    ai_msg = llm_with_tool.invoke(messages)\n",
    "\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "\n",
    "        # Meta Info\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "\n",
    "        return Command(\n",
    "            goto = \"additional_expert\",\n",
    "            update = {\"messages\": [ai_msg, tool_msg]}\n",
    "        )\n",
    "\n",
    "    return {\"messages\": [ai_msg]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e2ff01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5db86257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b03349ee60>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"additional_expert\", additional_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92d5253f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b03349ee60>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"multiplication_expert\", multiplication_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f6a3bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b03349ee60>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START, \"additional_expert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b86029db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001B02FAEDE10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = graph.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c75d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n",
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:1314: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  fields = getattr(cls, \"model_fields\", {}) or getattr(cls, \"__fields__\", {})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) * 12. Provide me the output\", additional_kwargs={}, response_metadata={}, id='45a2635b-f4a3-4877-b98e-022e2867f143'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9FBdiR3U9LFzsECjox8yGGBV', 'function': {'arguments': '{}', 'name': 'transfer_to_multiplication_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 86, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bx27aS2AyQWY2ACPqj4EzZ9enmJ8D', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b7de21e7-f06f-4717-ab43-22372183b83f-0', tool_calls=[{'name': 'transfer_to_multiplication_expert', 'args': {}, 'id': 'call_9FBdiR3U9LFzsECjox8yGGBV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 86, 'output_tokens': 15, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred', id='b78cf3db-9a11-4ffc-94ed-8b1ffb10afb0', tool_call_id='call_9FBdiR3U9LFzsECjox8yGGBV'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XLDC84GSyJcrMxlqldJODDEN', 'function': {'arguments': '{}', 'name': 'transfer_to_addition_expert'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 115, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bx27als6HerE5ouGa6c4yzr3hpzZ9', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5106afff-3935-491f-81d1-4f017feec9bb-0', tool_calls=[{'name': 'transfer_to_addition_expert', 'args': {}, 'id': 'call_XLDC84GSyJcrMxlqldJODDEN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 115, 'output_tokens': 32, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Successfully transferred', id='4021b5ee-2de1-42ae-a63e-4f341c642c63', tool_call_id='call_XLDC84GSyJcrMxlqldJODDEN'),\n",
       "  AIMessage(content='To solve \\\\( (3 + 5) \\\\times 12 \\\\), we first calculate:\\n\\n**Addition**: \\\\( 3 + 5 = 8 \\\\)\\n\\nNow, this result will be handed off to the multiplication expert for completion.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 144, 'total_tokens': 194, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bx27bWCZlXiKdWeiPqOCTWfMyQnO7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--00a2dd93-babb-4602-a29e-d8884908af75-0', usage_metadata={'input_tokens': 144, 'output_tokens': 50, 'total_tokens': 194, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\":[(\"user\",\"what's (3 + 5) * 12. Provide me the output\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140e2fe",
   "metadata": {},
   "source": [
    "### Realtime Tool Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "948b7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# search_tool=DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "346aa6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8c24300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search_tool=TavilySearch(tavily_api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc03fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'who is India current Vice President?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://en.wikipedia.org/wiki/List_of_vice_presidents_of_India',\n",
       "   'title': 'List of vice presidents of India - Wikipedia',\n",
       "   'content': \"Jagdeep Dhankhar  Elected as the vice president in 2022 defeating his rival candidate Margaret Alva of the Indian National Congress. First vice president to be born after India's becoming a republic in 1950.\",\n",
       "   'score': 0.8506799,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://vicepresidentofindia.nic.in/',\n",
       "   'title': 'Home | Vice President of India | Government of India',\n",
       "   'content': \"The Vice-President, Shri Jagdeep Dhankhar addressing the gathering at 'Sneh Milan Samaroh' in Jaipur, Rajathan on June 30, 2025.\",\n",
       "   'score': 0.82186085,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://x.com/vpindia?lang=en',\n",
       "   'title': 'Vice-President of India (@VPIndia) / X',\n",
       "   'content': \"Hon'ble Vice-President of India & Chairman, Rajya Sabha, Shri Jagdeep Dhankhar administered oath to the newly elected and nominated Members\",\n",
       "   'score': 0.7548612,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://vicepresidentofindia.nic.in/profile',\n",
       "   'title': 'Profile | Vice President of India | Government of India',\n",
       "   'content': \"The position of Hon'ble Vice President of India has been vacant since 22 July, 2025. Speeches · Press Releases · Messages from VPI · Media Gallery\",\n",
       "   'score': 0.5760895,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://en.wikipedia.org/wiki/Vice_President_of_India',\n",
       "   'title': 'Vice President of India - Wikipedia',\n",
       "   'content': 'The vice president is the Chairman of the Rajya Sabha and ranks 2nd in the Order of Precedence of India. Article 66 of the Constitution of India states',\n",
       "   'score': 0.42419788,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.34}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"who is India current Vice President?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b80fd58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c84c4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee43a6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f4dd9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\Harshit\\AppData\\Local\\Temp\\ipykernel_21708\\895088054.py:16: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
      "C:\\Users\\Harshit\\AppData\\Local\\Temp\\ipykernel_21708\\895088054.py:16: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "    ):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "        \n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a24f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully executed:\n",
      "\\`\\`\\`python\n",
      "\n",
      "x = 5\n",
      "y = x * 2\n",
      "print(y)\n",
      "\n",
      "\\`\\`\\`\n",
      "Stdout: 10\n",
      "\n",
      "\n",
      "If you have completed all tasks, respond with FINAL ANSWER.\n"
     ]
    }
   ],
   "source": [
    "print(python_repl_tool.invoke(code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8379f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(instruction:str)->str:\n",
    "    return  (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{instruction}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "059eabcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a helpful AI assistant, collaborating with other assistants. Use the provided tools to progress towards answering the question. If you are unable to fully answer, that's OK, another assistant with different tools  will help where you left off. Execute what you can to make progress. If you or any of the other assistants have the final answer or deliverable, prefix your response with FINAL ANSWER so the team knows to stop.\\nYou can only do research. You are working with a chart generator colleague.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_system_prompt(\"You can only do research. You are working with a chart generator colleague.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cc220aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "\n",
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message:\n",
    "        return END\n",
    "    \n",
    "    return goto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aea166dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1\n",
    "\n",
    "def research_node(state: MessagesState)-> Command[Literal[\"chart_generator\", END]]:\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools = [search_tool],\n",
    "        prompt = make_system_prompt(\n",
    "            \"You can only do research. You are working with a chart generator colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    last_message = result[\"messages\"][-1]\n",
    "\n",
    "    goto=get_next_node(last_message,\"chart_generator\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "\n",
    "    return Command(update= {\"messages\": result[\"messages\"]}, goto = goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ffb0f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2\n",
    "\n",
    "def chart_node(state: MessagesState)-> Command[Literal[\"researcher\", END]]:\n",
    "    chart_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools = [python_repl_tool],\n",
    "        prompt = make_system_prompt(\n",
    "            \"You can only generate charts. You are working with a researcher colleague.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = chart_agent.invoke(state)\n",
    "\n",
    "    last_message = result[\"messages\"][-1]\n",
    "\n",
    "    goto=get_next_node(last_message,\"researcher\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(content=result[\"messages\"][-1].content, name=\"chart_generator\")\n",
    "\n",
    "    return Command(update= {\"messages\": result[\"messages\"]}, goto= goto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f3cef5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001B02FCAA9C0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "780e58d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\openai\\_base_client.py:1017\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\httpx\\_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget the UK\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms GDP over the past 3 years, then make a line chart of it.Once you make the chart, finish.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mresearch_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresearch_node\u001b[39m(state: MessagesState)-> Command[Literal[\u001b[33m\"\u001b[39m\u001b[33mchart_generator\u001b[39m\u001b[33m\"\u001b[39m, END]]:\n\u001b[32m      4\u001b[39m     research_agent = create_react_agent(\n\u001b[32m      5\u001b[39m         llm,\n\u001b[32m      6\u001b[39m         tools = [search_tool],\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         ),\n\u001b[32m     10\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     result = \u001b[43mresearch_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     last_message = result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m     16\u001b[39m     goto=get_next_node(last_message,\u001b[33m\"\u001b[39m\u001b[33mchart_generator\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:507\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.call_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) -> StateSchema:\n\u001b[32m    506\u001b[39m     state = _get_model_input_state(state)\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     response = cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    509\u001b[39m     response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1130\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1044\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1085\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1086\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_retry(err.response):\n\u001b[32m   1022\u001b[39m     err.response.close()\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sleep_for_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\openai\\_base_client.py:1063\u001b[39m, in \u001b[36mSyncAPIClient._sleep_for_retry\u001b[39m\u001b[34m(self, retries_taken, max_retries, options, response)\u001b[39m\n\u001b[32m   1060\u001b[39m timeout = \u001b[38;5;28mself\u001b[39m._calculate_retry_timeout(remaining_retries, options, response.headers \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1061\u001b[39m log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\",\"get the UK's GDP over the past 3 years, then make a line chart of it.Once you make the chart, finish.\")],})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949c608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
