{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a99b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0\n",
    ")\n",
    "response=llm.invoke(\"what is length of wall of china?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a82cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out the length of the Great Wall of China. I remember hearing that it's really long, but I'm not exactly sure how long. I think it's somewhere in the thousands of kilometers, but I'm not certain. Let me try to break this down.\\n\\nFirst, I know the Great Wall is a series of fortifications built across several Chinese dynasties. It wasn't built all at once, so maybe that's why the length can vary. I've heard different numbers before, like 13,000 miles or something like that. But I also remember reading somewhere that it's actually shorter than that. Maybe the longer number includes all the branches and sections that aren't part of the main wall.\\n\\nI should consider the different dynasties that contributed to the wall. The Qin Dynasty, I think, was the first to start building it, but it was during the Han Dynasty that it started to take shape more. Then the Sui and Ming Dynasties did a lot of work on it. The Ming Dynasty, especially, is famous for building the most well-known parts of the wall with bricks and watchtowers.\\n\\nSo, the wall wasn't built as a single continuous structure. It was constructed in pieces, with different sections being added over time. Some parts are in better condition than others, especially the parts near Beijing, which are popular tourist spots. Other sections are more remote and might be less measured or accounted for.\\n\\nI also recall that in 2012, there was an official measurement done by the National Cultural Heritage Administration in China. They used more precise methods, maybe GPS or satellite imaging, to get a more accurate length. Before that, the commonly cited figure was around 13,171 miles, but after the survey, it was found to be longer, around 13,170 miles or 21,196 kilometers. Wait, that seems a bit confusing because 13,170 miles is about 21,196 kilometers, so maybe that's the accurate number now.\\n\\nBut I'm a bit confused because I've heard some sources say it's about 4,000 miles. Maybe that's just the main wall without including all the branches and parallel sections. So, the total length, including all the spurs and loops, is much longer. That makes sense because the wall wasn't just a straight line; it had various sections built for different strategic purposes.\\n\\nI should also think about how the wall was used. It wasn't just for defense; it also served as a border control, helping to regulate trade and immigration. So, having multiple sections and branches would make sense for those purposes. Each dynasty added their own parts, sometimes building over older sections or extending them.\\n\\nAnother thing to consider is that some parts of the wall have been damaged or eroded over time. Natural weathering, human activities, and the use of materials from the wall for other purposes have all contributed to sections being lost or destroyed. This might affect the total measured length because some parts are no longer there or are difficult to trace.\\n\\nI also wonder how they measured the wall. Before modern technology, they probably used manual surveys, which could be less accurate. With the use of satellites and GPS, they can now measure more precisely, which might explain why the length was underestimated before.\\n\\nSo, putting it all together, the Great Wall of China is a complex structure with multiple sections built over centuries. The total length, including all the branches and loops, is about 13,170 miles or 21,196 kilometers. This number comes from a more recent and accurate survey, which accounts for all the various parts of the wall, not just the main continuous structure.\\n\\nI think I've got a good grasp on it now. The key points are that the wall was built in segments by different dynasties, it's not a single straight line, and the total length includes all the additional sections beyond the main wall. The most accurate measurement as of now is around 13,170 miles or 21,196 kilometers.\\n</think>\\n\\nThe Great Wall of China, constructed over several centuries by various dynasties, is a complex series of fortifications. The most accurate measurement, conducted in 2012 using modern techniques like GPS and satellite imaging, determined its total length to be approximately 13,170 miles (21,196 kilometers). This figure includes all branches, loops, and parallel sections, reflecting the wall's strategic purposes beyond mere defense, such as border control and trade regulation. The structure's length was previously underestimated, but advanced survey methods now provide a more precise total.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615a7bc",
   "metadata": {},
   "source": [
    "### Our Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7897c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiple(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiple two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The product of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The Sum of a and b\n",
    "    \"\"\"\n",
    "\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Divide two integers.\n",
    "\n",
    "    Args:\n",
    "    a(int): The first integer\n",
    "    b(int): The second integer\n",
    "\n",
    "    Returns:\n",
    "        int: The result of division\n",
    "    \"\"\"\n",
    "\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Denominator cannot be zero.\")\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ccd96",
   "metadata": {},
   "source": [
    "### Inbuilt Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15901563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec5e472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Latest Current News: U.S., World, Entertainment, Health, Business, Technology, Politics, Sports. View the latest news and breaking news today for U.S., world, weather, entertainment, politics and health at CNN.com. Go to NBCNews.com for breaking news, videos, and the latest top stories in world news, business, politics, health and pop culture. Read the latest headlines, breaking news, and videos at APNews.com, the definitive source for independent journalism from every corner of the globe. CBS Sports HQ: Local News, Weather & More Want more highlights and less talk? Get the latest news coverage for your favorite sports, players, and teams on CBS Sports HQ.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the latest update on iphone17 release?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82411",
   "metadata": {},
   "source": [
    "### Binding all tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3214095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiple, add, divide, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac89f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295983af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'reasoning_content': 'Alright, the user sent \"hi\". I need to figure out how to respond. Since I\\'m an assistant, I should greet them back and offer help. I don\\'t see any specific request, so I\\'ll keep it friendly and open-ended. Maybe ask how I can assist them today. That should cover it.\\n'}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 367, 'total_tokens': 445, 'completion_time': 0.728821004, 'prompt_time': 0.033151349, 'queue_time': 0.2018065, 'total_time': 0.761972353}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'stop', 'logprobs': None}, id='run--58f737d5-6aa2-4bb9-9ac6-9ad6363c6a92-0', usage_metadata={'input_tokens': 367, 'output_tokens': 78, 'total_tokens': 445})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm_with_tools.invoke(\"hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01766026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f22e371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, so the user is asking, \"what is 2+2?\" That\\'s a pretty straightforward math problem. I need to figure out how to respond using the tools provided.\\n\\nLooking at the tools available, there\\'s an \"add\" function that takes two integers and returns their sum. That seems perfect for this query. I should use that function with a=2 and b=2.\\n\\nI need to make sure I format the tool call correctly. The function name should be \"add\" and the arguments should be a JSON object with a and b set to 2 each.\\n\\nSo, the tool call should look like {\"name\": \"add\", \"arguments\": {\"a\": 2, \"b\": 2}}. That should give the correct result of 4.\\n', 'tool_calls': [{'id': 'tydp96pwc', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 190, 'prompt_tokens': 373, 'total_tokens': 563, 'completion_time': 0.765018913, 'prompt_time': 0.036866259, 'queue_time': 0.20239549699999998, 'total_time': 0.801885172}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d4fe92fc-50c3-46fa-ae6a-07497c2b9d6a-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 2}, 'id': 'tydp96pwc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 373, 'output_tokens': 190, 'total_tokens': 563})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm_with_tools.invoke(\"what is 2+2?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6b64f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 2},\n",
       "  'id': 'tydp96pwc',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac11abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The TATA Group was founded in 1868 by Jamsetji Tata. As of 2023, it is 155 years old. \\n\\n', additional_kwargs={'reasoning_content': \"Okay, the user is asking about the current age of the TATA Group. I need to figure out how to respond to this. First, I should understand what the TATA Group is. From what I know, the TATA Group is a large conglomerate based in India, founded by Jamsetji Tata. \\n\\nI remember that Jamsetji Tata founded the group in the late 19th century. Specifically, I think it was around 1868 when he started the company. To find the current age, I need to subtract the founding year from the current year, which is 2023. \\n\\nSo, 2023 minus 1868 equals 155 years. That means the TATA Group is 155 years old as of 2023. \\n\\nI should make sure this information is accurate. Maybe I can cross-verify it with a quick search, but since I can't access external information, I'll rely on my existing knowledge. \\n\\nI think it's safe to say that the TATA Group is indeed over 150 years old, making it one of the oldest and most established conglomerates in India. \\n\\nTherefore, the current age of the TATA Group is 155 years.\\n\", 'tool_calls': [{'id': '7rw0z5erq', 'function': {'arguments': '{\"query\":\"TATA Group age 2023\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 377, 'total_tokens': 688, 'completion_time': 1.130909091, 'prompt_time': 0.033173678, 'queue_time': 0.202162144, 'total_time': 1.164082769}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5d7eabdb-c0b9-4fdb-b531-319056873df9-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'TATA Group age 2023'}, 'id': '7rw0z5erq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 377, 'output_tokens': 311, 'total_tokens': 688})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm_with_tools.invoke(\"what is a current age of the TATA Group?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c4d7421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'duckduckgo_search',\n",
       "  'args': {'query': 'TATA Group age 2023'},\n",
       "  'id': '7rw0z5erq',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bf16d",
   "metadata": {},
   "source": [
    "### Setting up Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1642d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a helpful assistant tasked with using search and performing arithmetic on a set of inputs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96a375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = [\"tell me what is 2+2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfed5e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You are a helpful assistant tasked with using search and performing arithmetic on a set of inputs.',\n",
       " 'tell me what is 2+2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[SYSTEM_PROMPT] + user_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ebd07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, END, START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cff10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68c6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(state: MessagesState):\n",
    "    user_question = state[\"messages\"]\n",
    "\n",
    "    input_question = [SYSTEM_PROMPT] + user_question\n",
    "\n",
    "    response = llm_with_tools.invoke(input_question)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "071d30b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16fdc958d70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"llm_decision_step\", function1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab4f891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='multiple', description='Multiple two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The product of a and b', args_schema=<class 'langchain_core.utils.pydantic.multiple'>, func=<function multiple at 0x0000016FDA3B34C0>),\n",
       " StructuredTool(name='add', description='Add two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The Sum of a and b', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x0000016FDA3B39C0>),\n",
       " StructuredTool(name='divide', description='Divide two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The result of division', args_schema=<class 'langchain_core.utils.pydantic.divide'>, func=<function divide at 0x0000016FDC767D80>),\n",
       " DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdcbef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16fdc958d70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "workflow.add_node(\"tools\", ToolNode(tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66a59644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16fdc958d70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START,\"llm_decision_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df6c643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16fdc958d70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "workflow.add_conditional_edges(\"llm_decision_step\",\n",
    "                            tools_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c98804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16fdc958d70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"tools\",\"llm_decision_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49a03068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000016FDC95B380>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23b388",
   "metadata": {},
   "source": [
    "### Experimenting with workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0dc06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[HumanMessage(content=\"What is 2 times of narendramodi's age?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72786e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What is 2 times of narendramodi's age?\", additional_kwargs={}, response_metadata={}, id='e3470021-fb11-4081-8781-0249d9f08d04'),\n",
       "  AIMessage(content=\"To find 2 times Narendra Modi's age, I'll first look up his current age using DuckDuckGo.\\n\\n\", additional_kwargs={'reasoning_content': 'Okay, so the user is asking, \"What is 2 times of narendramodi\\'s age?\" First, I need to figure out what exactly they\\'re asking for. It seems like they want to multiply Narendra Modi\\'s age by 2. \\n\\nTo do this, I need to find out how old Narendra Modi is. I don\\'t have that information stored, so I should use the DuckDuckGo search tool to look it up. \\n\\nI\\'ll call the duckduckgo_search function with the query \"Narendra Modi age\" to get the most accurate and up-to-date information. Once I have his age, I can then use the multiple function to calculate 2 times his age.\\n\\nI should make sure to handle any potential issues, like if the search doesn\\'t return a clear age or if there\\'s an error in the functions. But assuming everything works smoothly, I\\'ll get the age, multiply it by 2, and provide the result to the user.\\n', 'tool_calls': [{'id': '7z3cdraft', 'function': {'arguments': '{\"query\":\"Narendra Modi age\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 398, 'total_tokens': 686, 'completion_time': 1.0944248619999999, 'prompt_time': 0.03236599, 'queue_time': 0.20175503900000002, 'total_time': 1.126790852}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d55d5be3-1846-4528-9a4e-d6cdf08c870b-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Narendra Modi age'}, 'id': '7z3cdraft', 'type': 'tool_call'}], usage_metadata={'input_tokens': 398, 'output_tokens': 288, 'total_tokens': 686}),\n",
       "  ToolMessage(content='2 days ago · Narendra Modi (born September 17, 1950, Vadnagar, India) is an Indian politician and government official who rose to become a senior leader of the Bharatiya Janata Party (BJP). 6 days ago · 75: Age is just a reminder, Mohan Bhagwat’s retirement hint puts focus on Narendra Modi The retirement talk began after Bhagwat this week stressed the need for leaders to step … Jun 5, 2025 · Currently, Narendra Modi is the Prime Minister of India, having been in office since 2014. He is the 14th Prime Minister of India who had three consecutive terms on the post. He … Jul 9, 2025 · Explore complete details about Prime Minister Narendra Modi — his age, full name, salary, education, family, wife, and net worth in 2025. Get an overview of his early life, political … Dec 26, 2024 · Narendra Modi was born on September 17, 1950, in Vadnagar, a town in the state of Gujarat, India. He was the third of six children born to Damodardas Mulchand Modi, a street …', name='duckduckgo_search', id='a5b72771-9382-4848-95fb-c049f5633d54', tool_call_id='7z3cdraft'),\n",
       "  AIMessage(content='Narendra Modi is 73 years old as of 2023. Therefore, 2 times his age is:\\n\\n', additional_kwargs={'reasoning_content': 'Alright, so the user is asking for \"2 times of Narendra Modi\\'s age.\" First, I need to figure out how old Narendra Modi is. I remember that he was born in 1950, but I\\'m not exactly sure of the exact date. To get accurate information, I\\'ll use the DuckDuckGo search tool to look up his current age.\\n\\nAfter searching, I find that Narendra Modi was born on September 17, 1950. Now, to calculate his age in 2023, I subtract 1950 from 2023, which gives me 73 years old. \\n\\nNext, the user wants twice his age, so I need to multiply 73 by 2. That gives me 146. \\n\\nI should make sure that the information I have is up-to-date and accurate. Since the search results confirm his birth year as 1950, I can confidently proceed with the calculation. \\n\\nFinally, I\\'ll present the answer clearly, stating that Narendra Modi is 73 years old as of 2023 and that twice his age is 146.\\n', 'tool_calls': [{'id': 'wq25pj237', 'function': {'arguments': '{\"a\":2,\"b\":73}', 'name': 'multiple'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 275, 'prompt_tokens': 699, 'total_tokens': 974, 'completion_time': 1.079255624, 'prompt_time': 0.052725709, 'queue_time': 0.2017871, 'total_time': 1.131981333}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b7bc9bc2-c9e0-4698-9c19-15a7b521f801-0', tool_calls=[{'name': 'multiple', 'args': {'a': 2, 'b': 73}, 'id': 'wq25pj237', 'type': 'tool_call'}], usage_metadata={'input_tokens': 699, 'output_tokens': 275, 'total_tokens': 974}),\n",
       "  ToolMessage(content='146', name='multiple', id='8ae97b9d-b0b2-47d2-ae8a-055f60d77465', tool_call_id='wq25pj237'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Narendra Modi is 73 years old. Therefore, 2 times his age is 146.'}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 751, 'total_tokens': 774, 'completion_time': 0.083636364, 'prompt_time': 0.055336425, 'queue_time': 0.202983196, 'total_time': 0.138972789}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'stop', 'logprobs': None}, id='run--f538e209-b350-4d95-ab79-d14bf8e38b9a-0', usage_metadata={'input_tokens': 751, 'output_tokens': 23, 'total_tokens': 774})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What is 2 times of narendramodi's age?\", additional_kwargs={}, response_metadata={}, id='fff8bd46-1884-4137-a2f1-3e7102c614e6'),\n",
       "  AIMessage(content=\"To find 2 times Narendra Modi's age, I'll first look up his current age using DuckDuckGo.\\n\\n\", additional_kwargs={'reasoning_content': 'Okay, so the user is asking, \"What is 2 times of narendramodi\\'s age?\" First, I need to figure out what exactly they\\'re asking for. It seems like they want to multiply Narendra Modi\\'s age by 2. \\n\\nTo do this, I need to find out how old Narendra Modi is. I don\\'t have that information stored, so I should use the DuckDuckGo search tool to look it up. \\n\\nI\\'ll call the duckduckgo_search function with the query \"Narendra Modi age\" to get the most accurate and up-to-date information. Once I have his age, I can then use the multiple function to calculate 2 times his age.\\n\\nI should make sure to handle any potential issues, like if the search doesn\\'t return a clear age or if there\\'s an error in the functions. But assuming everything works smoothly, I\\'ll get the age, multiply it by 2, and provide the result to the user.\\n', 'tool_calls': [{'id': 'n96d7tc6g', 'function': {'arguments': '{\"query\":\"Narendra Modi age\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 398, 'total_tokens': 686, 'completion_time': 1.076413502, 'prompt_time': 0.032450224, 'queue_time': 0.202274057, 'total_time': 1.108863726}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1ade3383-27b4-4be4-aea6-c5a0670a698b-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Narendra Modi age'}, 'id': 'n96d7tc6g', 'type': 'tool_call'}], usage_metadata={'input_tokens': 398, 'output_tokens': 288, 'total_tokens': 686}),\n",
       "  ToolMessage(content=\"Narendra Damodardas Modi[a] (born 17 September 1950) is an Indian politician who has served as the prime minister of India since 2014. Modi was the chief minister of Gujarat from 2001 to 2014 … 2 days ago · Narendra Modi (born September 17, 1950, Vadnagar, India) is an Indian politician and government official who rose to become a senior leader of the Bharatiya Janata Party (BJP). Narendra Modi, the 14th Prime Minister of India, is a figure whose political journey is as intriguing as inspiring. Rising from humble beginnings, Modi's ascent through the ranks of the Rashtriya … Shri Narendra Modi was sworn-in as India’s Prime Minister for the third time on 9th June 2024, following another decisive victory in the 2024 Parliamentary elections. This victory marked the … Jul 8, 2025 · Prime Minister Narendra Modi received a warm ceremonial welcome in Brasilia on Tuesday, becoming the first Indian PM in 57 years to undertake a State Visit to Brazil, …\", name='duckduckgo_search', id='9a023fc7-733b-4e15-9c76-8a716080c803', tool_call_id='n96d7tc6g'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Alright, so the user is asking, \"What is 2 times of narendramodi\\'s age?\" First, I need to figure out Narendra Modi\\'s current age. I remember that he was born in 1950, but I\\'m not exactly sure of the exact date. To get accurate information, I\\'ll use the DuckDuckGo search tool to look up his age.\\n\\nAfter searching, I find that Narendra Modi was born on September 17, 1950. Now, to calculate his age in 2023, I subtract 1950 from 2023, which gives me 73 years old. \\n\\nNext, the user wants to know 2 times his age. So, I\\'ll use the multiplication function to calculate 2 multiplied by 73. That gives me 146.\\n\\nI should make sure to present the answer clearly, showing both the calculation and the final result. That way, the user can follow along and understand how I arrived at the answer.\\n', 'tool_calls': [{'id': 'emjwqwc8b', 'function': {'arguments': '{\"a\":2,\"b\":73}', 'name': 'multiple'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 243, 'prompt_tokens': 678, 'total_tokens': 921, 'completion_time': 0.883636364, 'prompt_time': 0.051255349, 'queue_time': 0.20942761199999999, 'total_time': 0.934891713}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5f9390a5-d438-414a-8c8a-f77f44a832a8-0', tool_calls=[{'name': 'multiple', 'args': {'a': 2, 'b': 73}, 'id': 'emjwqwc8b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 678, 'output_tokens': 243, 'total_tokens': 921}),\n",
       "  ToolMessage(content='146', name='multiple', id='fb6996fc-35ee-4b15-a898-ece94ae1717b', tool_call_id='emjwqwc8b'),\n",
       "  AIMessage(content='\\n\\nNarendra Modi is 73 years old. Therefore, 2 times his age is 146.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 732, 'total_tokens': 754, 'completion_time': 0.08, 'prompt_time': 0.054542739, 'queue_time': 0.20249993700000002, 'total_time': 0.134542739}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_76307ac09b', 'finish_reason': 'stop', 'logprobs': None}, id='run--0ec654d1-dea0-4d6c-b5d3-d0c04ccdb01e-0', usage_metadata={'input_tokens': 732, 'output_tokens': 22, 'total_tokens': 754})]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\" : [\"What is 2 times of narendramodi's age?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fab6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [HumanMessage(content=\"What is the speed of light in m/s and multiply it by 10?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=app.invoke({\"messages\":message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0b76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speed of light in meters per second is 299,792,458 m/s. When multiplied by 10, the result is 2,997,924,580 meters per second. \\n\\n**Step-by-Step Explanation:**\\n\\n1. **Identify the speed of light:** The exact speed of light in a vacuum is 299,792,458 meters per second.\\n2. **Multiply by 10:** \\n   \\\\[\\n   299,792,458 \\\\, \\\\text{m/s} \\\\times 10 = 2,997,924,580 \\\\, \\\\text{m/s}\\n   \\\\]\\n3. **Present the result:** The speed of light multiplied by 10 is 2,997,924,580 meters per second.\\n\\n**Answer:** 2,997,924,580 meters per second.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a03040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the speed of light in m/s and multiply it by 10?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The speed of light in meters per second is approximately 299,792,458 m/s. When multiplied by 10, the result is:\n",
      "Tool Calls:\n",
      "  multiple (c799v6z05)\n",
      " Call ID: c799v6z05\n",
      "  Args:\n",
      "    a: 299792458\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiple\n",
      "\n",
      "2997924580\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The speed of light is approximately **299,792,458 m/s**. Multiplying this by 10 gives:\n",
      "Tool Calls:\n",
      "  multiple (72k2f2520)\n",
      " Call ID: 72k2f2520\n",
      "  Args:\n",
      "    a: 299792458\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiple\n",
      "\n",
      "2997924580\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The speed of light in meters per second is 299,792,458 m/s. When multiplied by 10, the result is 2,997,924,580 meters per second. \n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Identify the speed of light:** The exact speed of light in a vacuum is 299,792,458 meters per second.\n",
      "2. **Multiply by 10:** \n",
      "   \\[\n",
      "   299,792,458 \\, \\text{m/s} \\times 10 = 2,997,924,580 \\, \\text{m/s}\n",
      "   \\]\n",
      "3. **Present the result:** The speed of light multiplied by 10 is 2,997,924,580 meters per second.\n",
      "\n",
      "**Answer:** 2,997,924,580 meters per second.\n"
     ]
    }
   ],
   "source": [
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240fcc14",
   "metadata": {},
   "source": [
    "## Workflow2: Custom tool using Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05ed01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43a776fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_stock_price(ticker: str)->str:\n",
    "    \"\"\"\n",
    "    Fetches the previous closing price of a given stock ticker from Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        ticker(str): The stock ticker symbol (e.g. 'AAPL', 'TSLA', 'NIFTY.BO')\n",
    "\n",
    "    Returns:\n",
    "        str: A message with stock's previous closing price\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        price = stock.info.get('previousClose')\n",
    "        if price is None:\n",
    "            return f\"Could not fetch price for ticker '{ticker}'.\"\n",
    "        return f\"The last closing price of {ticker.upper()} was ${price:.2f}.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while fetching stock data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d48ffe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last closing price of AAPL was $210.16.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8598eea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last closing price of TSLA was $321.67.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(\"TSLA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4fb7bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='multiple', description='Multiple two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The product of a and b', args_schema=<class 'langchain_core.utils.pydantic.multiple'>, func=<function multiple at 0x0000016FDA3B34C0>),\n",
       " StructuredTool(name='add', description='Add two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The Sum of a and b', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x0000016FDA3B39C0>),\n",
       " StructuredTool(name='divide', description='Divide two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The result of division', args_schema=<class 'langchain_core.utils.pydantic.divide'>, func=<function divide at 0x0000016FDC767D80>),\n",
       " DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fedab02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.append(get_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61cacda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='multiple', description='Multiple two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The product of a and b', args_schema=<class 'langchain_core.utils.pydantic.multiple'>, func=<function multiple at 0x0000016FDA3B34C0>),\n",
       " StructuredTool(name='add', description='Add two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The Sum of a and b', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x0000016FDA3B39C0>),\n",
       " StructuredTool(name='divide', description='Divide two integers.\\n\\nArgs:\\na(int): The first integer\\nb(int): The second integer\\n\\nReturns:\\n    int: The result of division', args_schema=<class 'langchain_core.utils.pydantic.divide'>, func=<function divide at 0x0000016FDC767D80>),\n",
       " DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text')),\n",
       " StructuredTool(name='get_stock_price', description=\"Fetches the previous closing price of a given stock ticker from Yahoo Finance.\\n\\nArgs:\\n    ticker(str): The stock ticker symbol (e.g. 'AAPL', 'TSLA', 'NIFTY.BO')\\n\\nReturns:\\n    str: A message with stock's previous closing price\", args_schema=<class 'langchain_core.utils.pydantic.get_stock_price'>, func=<function get_stock_price at 0x0000016FEF589BC0>)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "983ad97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2edb52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke(\"can you give me a latest stock price of adani greens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad0f7dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12aef477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_stock_price',\n",
       "  'args': {'ticker': 'ADANIGREEN.NS'},\n",
       "  'id': '8syr3t8ab',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e78ca104",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = SystemMessage(\n",
    "    content=\"You are a helpful assistant tasked with using search, the yahoo finance tool and performing arithmetic on a set of inputs.\"\n",
    ")\n",
    "def function_1(state:MessagesState):\n",
    "    \n",
    "    user_question=state[\"messages\"]\n",
    "    \n",
    "    input_question = [SYSTEM_PROMPT]+user_question\n",
    "    \n",
    "    response = llm_with_tools.invoke(input_question)\n",
    "    \n",
    "    return {\n",
    "        \"messages\":[response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb3a0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"llm_decision_step\", function_1)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "workflow.add_edge(START, \"llm_decision_step\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_decision_step\",\n",
    "    tools_condition,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"llm_decision_step\")\n",
    "react_graph2 = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98db026e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000016FDFB17250>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react_graph2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38f55af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool_call>{\"name\":\"add\",\"arguments\":{\"a\":1000,\"b\":210.16}}</tool_call>\\n\\nThe result of adding 1000 to the current stock price of Apple (210.16) is **1210.16**.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33madd 1000 in the current stock price of Apple.\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m messages = \u001b[43mreact_graph2\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2532\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2533\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2534\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2541\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2544\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mfunction_1\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      6\u001b[39m user_question=state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m input_question = [SYSTEM_PROMPT]+user_question\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m:[response]\n\u001b[32m     14\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    368\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     **kwargs: Any,\n\u001b[32m    374\u001b[39m ) -> BaseMessage:\n\u001b[32m    375\u001b[39m     config = ensure_config(config)\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    377\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    388\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:536\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    531\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    532\u001b[39m params = {\n\u001b[32m    533\u001b[39m     **params,\n\u001b[32m    534\u001b[39m     **kwargs,\n\u001b[32m    535\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\groq\\_base_client.py:1232\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1220\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1227\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1228\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1229\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1230\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1231\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\groq\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool_call>{\"name\":\"add\",\"arguments\":{\"a\":1000,\"b\":210.16}}</tool_call>\\n\\nThe result of adding 1000 to the current stock price of Apple (210.16) is **1210.16**.'}}",
      "During task with name 'llm_decision_step' and id '42df138e-b3f5-5c6f-ac8f-066f6fe619b1'"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"add 1000 in the current stock price of Apple.\")]\n",
    "messages = react_graph2.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6474e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "add 1000 in the current stock price of Apple.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_stock_price (g81mzsh4w)\n",
      " Call ID: g81mzsh4w\n",
      "  Args:\n",
      "    ticker: AAPL\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_stock_price\n",
      "\n",
      "The last closing price of AAPL was $210.16.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current stock price of Apple (AAPL) is **$210.16**. Adding 1000 to this price gives:\n",
      "\n",
      "**$1,210.16**\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28ca8e55",
   "metadata": {},
   "outputs": [
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mcan you give me current stock price of Apple with the latest news of the Apple.\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m messages = \u001b[43mreact_graph2\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\AgenticAI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2559\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2551\u001b[39m     msg = create_error_message(\n\u001b[32m   2552\u001b[39m         message=(\n\u001b[32m   2553\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2558\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2559\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2560\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2561\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"can you give me current stock price of Apple with the latest news of the Apple.\")]\n",
    "messages = react_graph2.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbd299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
